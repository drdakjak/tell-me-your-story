{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from handler import handler, get_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_response(response):\n",
    "    print('Response')\n",
    "    display(Markdown(response['response']))\n",
    "    print('Tailored Section')\n",
    "    display(Markdown(response['tailored_section']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Applied Machine Learning Scientist \n",
       "\n",
       "Nov. 2016 - Feb. 2019\n",
       "\n",
       "- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \n",
       "- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \n",
       "- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \n",
       "- Highlighted projects: \n",
       "    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \n",
       "    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \n",
       "    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \n",
       "    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \n",
       "    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \n",
       "    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \n",
       "    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_section = \"## Applied Machine Learning Scientist \\n\\nNov. 2016 - Feb. 2019\\n\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\n- Highlighted projects: \\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\"\n",
    "display(Markdown(original_section))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Applied Machine Learning Scientist**  \n",
       "*Nov. 2016 - Feb. 2019*\n",
       "\n",
       "- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\n",
       "  \n",
       "- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\n",
       "\n",
       "- **Model Optimization and Evaluation:** \n",
       "  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\n",
       "  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\n",
       "  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\n",
       "\n",
       "- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tailored_section = '\\n**Applied Machine Learning Scientist**  \\n*Nov. 2016 - Feb. 2019*\\n\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\n  \\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\n\\n- **Model Optimization and Evaluation:** \\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\n\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\\n'\n",
    "display(Markdown(tailored_section))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event(file_name):\n",
    "    path = f\"events/{file_name}\"\n",
    "    with open(path, 'r') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_1 = get_event(\"event_1.json\")\n",
    "conversation_id = event_1['body']['conversation_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You\\'re an expert resume writer. \\n\\n1. Help tailor this resume section to match job requirements.\\n2. Comunicate with the user to understand their needs.\\n3. Ask for clarification if needed. \\n\\nYou have access to the Original Section of the Resume and the Job Requirements extracted from the job post. \\nMoreover, you can use a tool for getting a current tailored section.\\n\\nAlways split the response to the two parts in this format:\\n{\\n    \"response\": \"The response that will be showed to the user.\",\\n    \"tailored_section\": \"If change is required, the newly tailored section. Can be empty string if no update is required.\"\\n}\\n\\n-------------------------------\\n\\nOriginal Section:\\n## Applied Machine Learning Scientist \\n\\nNov. 2016 - Feb. 2019\\n\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\n- Highlighted projects: \\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\\n\\n-------------------------------\\n\\nJob Requirements:\\n**Required Qualifications:**\\n1. Bachelor\\'s degree or equivalent practical experience.\\n2. 2 years of experience with software development in one or more programming languages, and with data structures or algorithms.\\n3. 2 years of experience with machine learning algorithms and tools (e.g., TensorFlow), artificial intelligence, deep learning, or natural language processing.\\n4. Experience with Large Language Models, NLP, or Generative AI.\\n5. Experience with Coding, Experiment Design, Data Analysis.\\n6. Experience with recommendation systems/rankings/predictions.\\n\\n**Preferred Qualifications:**\\n1. Master\\'s degree or PhD in Computer Science or related technical fields.\\n2. Experience developing accessible technologies.\\n3. Experience with C++, Statistical Analysis, Python.\\n4. Experience with quality work in either serving quality or data quality.\\n5. Experience as a data analyst/scientist.\\n6. Experience in understanding user behavior (i.e., mathematical modeling or social science background).\\n\\n**Key Technical Skills:**\\n1. Programming languages (specific languages not mentioned, but implied).\\n2. Machine learning algorithms and tools (e.g., TensorFlow).\\n3. Large Language Models, NLP, or Generative AI.\\n4. C++, Statistical Analysis, Python.\\n5. Data structures and algorithms.\\n6. Experiment Design.\\n7. Data Analysis.\\n8. Recommendation systems/rankings/predictions.\\n\\n**Soft Skills:**\\n1. Versatility.\\n2. Leadership qualities.\\n3. Enthusiasm to take on new problems.\\n\\n**Education Requirements:**\\n1. Bachelor\\'s degree or equivalent practical experience (required).\\n2. Master\\'s degree or PhD in Computer Science or related technical fields (preferred).\\n\\n**Experience Level:**\\n1. Minimum of 2 years of experience in software development and machine learning (required).\\n2. Additional experience in data analysis, recommendation systems, and understanding user behavior is preferred.\\n\\n**Industry-Specific Keywords:**\\n1. Software engineering.\\n2. Artificial intelligence.\\n3. Natural language processing.\\n4. Large-scale system design.\\n5. E-commerce.\\n6. User experience (UX).\\n7. Digital world.\\n\\n**Responsibilities and Duties:**\\n1. Work in coding, modeling, and analysis.\\n2. Identify or create relevant signals for modeling.\\n3. Combine signals into a model for offline evaluation.\\n4. Integrate models into the production stack (e.g., search and shopping) and initiate live experiments.\\n\\n**Company Values or Culture Fit:**\\n1. Commitment to equal employment opportunity and diversity.\\n2. Emphasis on innovation and fresh ideas.\\n3. Focus on collaboration with the commerce ecosystem.\\n4. Support for both large retailers and small local merchants.\\n\\n')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_message_history(conversation_id=conversation_id).messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The original section of your resume is titled 'Applied Machine Learning Scientist' and includes your experience from November 2016 to February 2019. It details your work on recommender systems, data processing and analysis, collaboration with ML engineering teams, and highlights various projects related to model improvement, recommendation diversification, hyperparameter optimization, offline evaluation frameworks, A/B/n test evaluation, production implementation, and contextual bandits research."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tailored Section\n"
     ]
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = handler(event_1, None)\n",
    "format_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You\\'re an expert resume writer. \\n\\n1. Help tailor this resume section to match job requirements.\\n2. Comunicate with the user to understand their needs.\\n3. Ask for clarification if needed. \\n\\nYou have access to the Original Section of the Resume and the Job Requirements extracted from the job post. \\nMoreover, you can use a tool for getting a current tailored section.\\n\\nAlways split the response to the two parts in this format:\\n{\\n    \"response\": \"The response that will be showed to the user.\",\\n    \"tailored_section\": \"If change is required, the newly tailored section. Can be empty string if no update is required.\"\\n}\\n\\n-------------------------------\\n\\nOriginal Section:\\n## Applied Machine Learning Scientist \\n\\nNov. 2016 - Feb. 2019\\n\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\n- Highlighted projects: \\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\\n\\n-------------------------------\\n\\nJob Requirements:\\n**Required Qualifications:**\\n1. Bachelor\\'s degree or equivalent practical experience.\\n2. 2 years of experience with software development in one or more programming languages, and with data structures or algorithms.\\n3. 2 years of experience with machine learning algorithms and tools (e.g., TensorFlow), artificial intelligence, deep learning, or natural language processing.\\n4. Experience with Large Language Models, NLP, or Generative AI.\\n5. Experience with Coding, Experiment Design, Data Analysis.\\n6. Experience with recommendation systems/rankings/predictions.\\n\\n**Preferred Qualifications:**\\n1. Master\\'s degree or PhD in Computer Science or related technical fields.\\n2. Experience developing accessible technologies.\\n3. Experience with C++, Statistical Analysis, Python.\\n4. Experience with quality work in either serving quality or data quality.\\n5. Experience as a data analyst/scientist.\\n6. Experience in understanding user behavior (i.e., mathematical modeling or social science background).\\n\\n**Key Technical Skills:**\\n1. Programming languages (specific languages not mentioned, but implied).\\n2. Machine learning algorithms and tools (e.g., TensorFlow).\\n3. Large Language Models, NLP, or Generative AI.\\n4. C++, Statistical Analysis, Python.\\n5. Data structures and algorithms.\\n6. Experiment Design.\\n7. Data Analysis.\\n8. Recommendation systems/rankings/predictions.\\n\\n**Soft Skills:**\\n1. Versatility.\\n2. Leadership qualities.\\n3. Enthusiasm to take on new problems.\\n\\n**Education Requirements:**\\n1. Bachelor\\'s degree or equivalent practical experience (required).\\n2. Master\\'s degree or PhD in Computer Science or related technical fields (preferred).\\n\\n**Experience Level:**\\n1. Minimum of 2 years of experience in software development and machine learning (required).\\n2. Additional experience in data analysis, recommendation systems, and understanding user behavior is preferred.\\n\\n**Industry-Specific Keywords:**\\n1. Software engineering.\\n2. Artificial intelligence.\\n3. Natural language processing.\\n4. Large-scale system design.\\n5. E-commerce.\\n6. User experience (UX).\\n7. Digital world.\\n\\n**Responsibilities and Duties:**\\n1. Work in coding, modeling, and analysis.\\n2. Identify or create relevant signals for modeling.\\n3. Combine signals into a model for offline evaluation.\\n4. Integrate models into the production stack (e.g., search and shopping) and initiate live experiments.\\n\\n**Company Values or Culture Fit:**\\n1. Commitment to equal employment opportunity and diversity.\\n2. Emphasis on innovation and fresh ideas.\\n3. Focus on collaboration with the commerce ecosystem.\\n4. Support for both large retailers and small local merchants.\\n\\n'),\n",
       " HumanMessage(content='Can you tell me what the original section is?'),\n",
       " AIMessage(content='{\\n    \"response\": \"The original section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes your experience from November 2016 to February 2019. It details your work on recommender systems, data processing and analysis, collaboration with ML engineering teams, and highlights various projects related to model improvement, recommendation diversification, hyperparameter optimization, offline evaluation frameworks, A/B/n test evaluation, production implementation, and contextual bandits research.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('1233'), 'completion_tokens': Decimal('99'), 'prompt_tokens': Decimal('1134'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-d9642683-a937-43c7-b17f-7f67afc21796-0', usage_metadata={'input_tokens': 1134, 'output_tokens': 99, 'total_tokens': 1233})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_message_history(conversation_id=conversation_id).messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_2 = get_event(\"event_2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The tailored section of your resume is titled 'Applied Machine Learning Scientist' and includes your experience from November 2016 to February 2019. It highlights your work on recommender systems, data processing and analysis, model optimization and evaluation, as well as research and collaboration. The section emphasizes your achievements and the tools you used, aligning closely with the job requirements."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tailored Section\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Applied Machine Learning Scientist**  \n",
       "*Nov. 2016 - Feb. 2019*  \n",
       "\n",
       "- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.  \n",
       "  \n",
       "- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.  \n",
       "  \n",
       "- **Model Optimization and Evaluation:**   \n",
       "  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \n",
       "  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \n",
       "  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.  \n",
       "  \n",
       "- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = handler(event_2, None)\n",
    "format_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You\\'re an expert resume writer. \\n\\n1. Help tailor this resume section to match job requirements.\\n2. Comunicate with the user to understand their needs.\\n3. Ask for clarification if needed. \\n\\nYou have access to the Original Section of the Resume and the Job Requirements extracted from the job post. \\nMoreover, you can use a tool for getting a current tailored section.\\n\\nAlways split the response to the two parts in this format:\\n{\\n    \"response\": \"The response that will be showed to the user.\",\\n    \"tailored_section\": \"If change is required, the newly tailored section. Can be empty string if no update is required.\"\\n}\\n\\n-------------------------------\\n\\nOriginal Section:\\n## Applied Machine Learning Scientist \\n\\nNov. 2016 - Feb. 2019\\n\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\n- Highlighted projects: \\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\\n\\n-------------------------------\\n\\nJob Requirements:\\n**Required Qualifications:**\\n1. Bachelor\\'s degree or equivalent practical experience.\\n2. 2 years of experience with software development in one or more programming languages, and with data structures or algorithms.\\n3. 2 years of experience with machine learning algorithms and tools (e.g., TensorFlow), artificial intelligence, deep learning, or natural language processing.\\n4. Experience with Large Language Models, NLP, or Generative AI.\\n5. Experience with Coding, Experiment Design, Data Analysis.\\n6. Experience with recommendation systems/rankings/predictions.\\n\\n**Preferred Qualifications:**\\n1. Master\\'s degree or PhD in Computer Science or related technical fields.\\n2. Experience developing accessible technologies.\\n3. Experience with C++, Statistical Analysis, Python.\\n4. Experience with quality work in either serving quality or data quality.\\n5. Experience as a data analyst/scientist.\\n6. Experience in understanding user behavior (i.e., mathematical modeling or social science background).\\n\\n**Key Technical Skills:**\\n1. Programming languages (specific languages not mentioned, but implied).\\n2. Machine learning algorithms and tools (e.g., TensorFlow).\\n3. Large Language Models, NLP, or Generative AI.\\n4. C++, Statistical Analysis, Python.\\n5. Data structures and algorithms.\\n6. Experiment Design.\\n7. Data Analysis.\\n8. Recommendation systems/rankings/predictions.\\n\\n**Soft Skills:**\\n1. Versatility.\\n2. Leadership qualities.\\n3. Enthusiasm to take on new problems.\\n\\n**Education Requirements:**\\n1. Bachelor\\'s degree or equivalent practical experience (required).\\n2. Master\\'s degree or PhD in Computer Science or related technical fields (preferred).\\n\\n**Experience Level:**\\n1. Minimum of 2 years of experience in software development and machine learning (required).\\n2. Additional experience in data analysis, recommendation systems, and understanding user behavior is preferred.\\n\\n**Industry-Specific Keywords:**\\n1. Software engineering.\\n2. Artificial intelligence.\\n3. Natural language processing.\\n4. Large-scale system design.\\n5. E-commerce.\\n6. User experience (UX).\\n7. Digital world.\\n\\n**Responsibilities and Duties:**\\n1. Work in coding, modeling, and analysis.\\n2. Identify or create relevant signals for modeling.\\n3. Combine signals into a model for offline evaluation.\\n4. Integrate models into the production stack (e.g., search and shopping) and initiate live experiments.\\n\\n**Company Values or Culture Fit:**\\n1. Commitment to equal employment opportunity and diversity.\\n2. Emphasis on innovation and fresh ideas.\\n3. Focus on collaboration with the commerce ecosystem.\\n4. Support for both large retailers and small local merchants.\\n\\n'),\n",
       " HumanMessage(content='Can you tell me what the original section is?'),\n",
       " AIMessage(content='{\\n    \"response\": \"The original section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes your experience from November 2016 to February 2019. It details your work on recommender systems, data processing and analysis, collaboration with ML engineering teams, and highlights various projects related to model improvement, recommendation diversification, hyperparameter optimization, offline evaluation frameworks, A/B/n test evaluation, production implementation, and contextual bandits research.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('1233'), 'completion_tokens': Decimal('99'), 'prompt_tokens': Decimal('1134'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-d9642683-a937-43c7-b17f-7f67afc21796-0', usage_metadata={'input_tokens': 1134, 'output_tokens': 99, 'total_tokens': 1233}),\n",
       " HumanMessage(content='Can you tell me what the tailored section is?'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None, 'tool_calls': [{'type': 'function', 'id': 'call_Ib9rUb3u7bCK4HobUTFkvjRr', 'function': {'name': 'get_current_tailored_section', 'arguments': '{}'}}]}, response_metadata={'token_usage': {'total_tokens': Decimal('1263'), 'completion_tokens': Decimal('13'), 'prompt_tokens': Decimal('1250'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-fe8cd5bf-7cd3-42ba-9bb3-f3fb4c886f67-0', tool_calls=[{'name': 'get_current_tailored_section', 'args': {}, 'id': 'call_Ib9rUb3u7bCK4HobUTFkvjRr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1250, 'output_tokens': 13, 'total_tokens': 1263}),\n",
       " ToolMessage(content='\\n**Applied Machine Learning Scientist**  \\n*Nov. 2016 - Feb. 2019*\\n\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\n  \\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\n\\n- **Model Optimization and Evaluation:** \\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\n\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\\n', name='get_current_tailored_section', tool_call_id='call_Ib9rUb3u7bCK4HobUTFkvjRr'),\n",
       " AIMessage(content='{\\n    \"response\": \"The tailored section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes your experience from November 2016 to February 2019. It highlights your work on recommender systems, data processing and analysis, model optimization and evaluation, as well as research and collaboration. The section emphasizes your achievements and the tools you used, aligning closely with the job requirements.\",\\n    \"tailored_section\": \"**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*  \\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.  \\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.  \\\\n  \\\\n- **Model Optimization and Evaluation:**   \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.  \\\\n  \\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('1907'), 'completion_tokens': Decimal('375'), 'prompt_tokens': Decimal('1532'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-ad0e7dfb-0edf-414a-94d6-d2c19e6ff345-0', usage_metadata={'input_tokens': 1532, 'output_tokens': 375, 'total_tokens': 1907})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_message_history(conversation_id=conversation_id).messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_3 = get_event(\"event_3.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I can certainly include your co-authorship of the workshop on recommendation systems at the ML Prague conference. This will enhance your experience and showcase your involvement in the field. Let me update the tailored section accordingly."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tailored Section\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Applied Machine Learning Scientist**  \n",
       "*Nov. 2016 - Feb. 2019*  \n",
       "\n",
       "- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.  \n",
       "  \n",
       "- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.  \n",
       "  \n",
       "- **Model Optimization and Evaluation:**   \n",
       "  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \n",
       "  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \n",
       "  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.  \n",
       "  \n",
       "- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Co-authored a workshop on recommendation systems at the ML Prague conference. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = handler(event_3, None)\n",
    "format_response(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You\\'re an expert resume writer. \\n\\n1. Help tailor this resume section to match job requirements.\\n2. Comunicate with the user to understand their needs.\\n3. Ask for clarification if needed. \\n\\nYou have access to the Original Section of the Resume and the Job Requirements extracted from the job post. \\nMoreover, you can use a tool for getting a current tailored section.\\n\\nAlways split the response to the two parts in this format:\\n{\\n    \"response\": \"The response that will be showed to the user.\",\\n    \"tailored_section\": \"If change is required, the newly tailored section. Can be empty string if no update is required.\"\\n}\\n\\n-------------------------------\\n\\nOriginal Section:\\n## Applied Machine Learning Scientist \\n\\nNov. 2016 - Feb. 2019\\n\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\n- Highlighted projects: \\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\\n\\n-------------------------------\\n\\nJob Requirements:\\n**Required Qualifications:**\\n1. Bachelor\\'s degree or equivalent practical experience.\\n2. 2 years of experience with software development in one or more programming languages, and with data structures or algorithms.\\n3. 2 years of experience with machine learning algorithms and tools (e.g., TensorFlow), artificial intelligence, deep learning, or natural language processing.\\n4. Experience with Large Language Models, NLP, or Generative AI.\\n5. Experience with Coding, Experiment Design, Data Analysis.\\n6. Experience with recommendation systems/rankings/predictions.\\n\\n**Preferred Qualifications:**\\n1. Master\\'s degree or PhD in Computer Science or related technical fields.\\n2. Experience developing accessible technologies.\\n3. Experience with C++, Statistical Analysis, Python.\\n4. Experience with quality work in either serving quality or data quality.\\n5. Experience as a data analyst/scientist.\\n6. Experience in understanding user behavior (i.e., mathematical modeling or social science background).\\n\\n**Key Technical Skills:**\\n1. Programming languages (specific languages not mentioned, but implied).\\n2. Machine learning algorithms and tools (e.g., TensorFlow).\\n3. Large Language Models, NLP, or Generative AI.\\n4. C++, Statistical Analysis, Python.\\n5. Data structures and algorithms.\\n6. Experiment Design.\\n7. Data Analysis.\\n8. Recommendation systems/rankings/predictions.\\n\\n**Soft Skills:**\\n1. Versatility.\\n2. Leadership qualities.\\n3. Enthusiasm to take on new problems.\\n\\n**Education Requirements:**\\n1. Bachelor\\'s degree or equivalent practical experience (required).\\n2. Master\\'s degree or PhD in Computer Science or related technical fields (preferred).\\n\\n**Experience Level:**\\n1. Minimum of 2 years of experience in software development and machine learning (required).\\n2. Additional experience in data analysis, recommendation systems, and understanding user behavior is preferred.\\n\\n**Industry-Specific Keywords:**\\n1. Software engineering.\\n2. Artificial intelligence.\\n3. Natural language processing.\\n4. Large-scale system design.\\n5. E-commerce.\\n6. User experience (UX).\\n7. Digital world.\\n\\n**Responsibilities and Duties:**\\n1. Work in coding, modeling, and analysis.\\n2. Identify or create relevant signals for modeling.\\n3. Combine signals into a model for offline evaluation.\\n4. Integrate models into the production stack (e.g., search and shopping) and initiate live experiments.\\n\\n**Company Values or Culture Fit:**\\n1. Commitment to equal employment opportunity and diversity.\\n2. Emphasis on innovation and fresh ideas.\\n3. Focus on collaboration with the commerce ecosystem.\\n4. Support for both large retailers and small local merchants.\\n\\n'),\n",
       " HumanMessage(content='Can you tell me what the original section is?'),\n",
       " AIMessage(content='{\\n    \"response\": \"The original section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes your experience from November 2016 to February 2019. It details your work on recommender systems, data processing and analysis, collaboration with ML engineering teams, and highlights various projects related to model improvement, recommendation diversification, hyperparameter optimization, offline evaluation frameworks, A/B/n test evaluation, production implementation, and contextual bandits research.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('1233'), 'completion_tokens': Decimal('99'), 'prompt_tokens': Decimal('1134'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-d9642683-a937-43c7-b17f-7f67afc21796-0', usage_metadata={'input_tokens': 1134, 'output_tokens': 99, 'total_tokens': 1233}),\n",
       " HumanMessage(content='Can you tell me what the tailored section is?'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None, 'tool_calls': [{'type': 'function', 'id': 'call_Ib9rUb3u7bCK4HobUTFkvjRr', 'function': {'name': 'get_current_tailored_section', 'arguments': '{}'}}]}, response_metadata={'token_usage': {'total_tokens': Decimal('1263'), 'completion_tokens': Decimal('13'), 'prompt_tokens': Decimal('1250'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-fe8cd5bf-7cd3-42ba-9bb3-f3fb4c886f67-0', tool_calls=[{'name': 'get_current_tailored_section', 'args': {}, 'id': 'call_Ib9rUb3u7bCK4HobUTFkvjRr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1250, 'output_tokens': 13, 'total_tokens': 1263}),\n",
       " ToolMessage(content='\\n**Applied Machine Learning Scientist**  \\n*Nov. 2016 - Feb. 2019*\\n\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\n  \\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\n\\n- **Model Optimization and Evaluation:** \\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\n\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\\n', name='get_current_tailored_section', tool_call_id='call_Ib9rUb3u7bCK4HobUTFkvjRr'),\n",
       " AIMessage(content='{\\n    \"response\": \"The tailored section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes your experience from November 2016 to February 2019. It highlights your work on recommender systems, data processing and analysis, model optimization and evaluation, as well as research and collaboration. The section emphasizes your achievements and the tools you used, aligning closely with the job requirements.\",\\n    \"tailored_section\": \"**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*  \\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.  \\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.  \\\\n  \\\\n- **Model Optimization and Evaluation:**   \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.  \\\\n  \\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('1907'), 'completion_tokens': Decimal('375'), 'prompt_tokens': Decimal('1532'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-ad0e7dfb-0edf-414a-94d6-d2c19e6ff345-0', usage_metadata={'input_tokens': 1532, 'output_tokens': 375, 'total_tokens': 1907}),\n",
       " HumanMessage(content='I forgot to mention that I co-authored a workshop on the recommendation systems at the conference ML Prague. Can you include that?'),\n",
       " AIMessage(content='{\\n    \"response\": \"I can certainly include your co-authorship of the workshop on recommendation systems at the ML Prague conference. This will enhance your experience and showcase your involvement in the field. Let me update the tailored section accordingly.\",\\n    \"tailored_section\": \"**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*  \\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.  \\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.  \\\\n  \\\\n- **Model Optimization and Evaluation:**   \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.  \\\\n  \\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Co-authored a workshop on recommendation systems at the ML Prague conference. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2297'), 'completion_tokens': Decimal('357'), 'prompt_tokens': Decimal('1940'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-d562cd00-673c-4f82-b1db-b586c4df753b-0', usage_metadata={'input_tokens': 1940, 'output_tokens': 357, 'total_tokens': 2297})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_message_history(conversation_id=conversation_id).messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_4 = get_event(\"event_4.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I can definitely make the tailored section more concise while still highlighting your key achievements and experiences. Heres a more streamlined version."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tailored Section\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Applied Machine Learning Scientist**  \n",
       "*Nov. 2016 - Feb. 2019*  \n",
       "\n",
       "- **Recommender Systems Development:** Developed collaborative filtering and online ML systems for lifestyle, news, and video content, achieving a double-digit increase in key metrics and reaching over half of the Czech internet population.  \n",
       "  \n",
       "- **Data Processing:** Analyzed terabytes of logs daily using PySpark, creating a proprietary framework for data manipulation and quality assurance.  \n",
       "  \n",
       "- **Model Optimization:** Enhanced online ML models through data cleaning and feature engineering. Developed an offline evaluation framework and coauthored an A/B/n test evaluation library.  \n",
       "  \n",
       "- **Research and Collaboration:** Researched contextual bandits, leading to a publication at SIGIR 2019 and co-authored a workshop on recommendation systems at ML Prague. Collaborated with ML engineering teams to ensure code quality and successful production transitions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = handler(event_4, None)\n",
    "format_response(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You\\'re an expert resume writer. \\n\\n1. Help tailor this resume section to match job requirements.\\n2. Comunicate with the user to understand their needs.\\n3. Ask for clarification if needed. \\n\\nYou have access to the Original Section of the Resume and the Job Requirements extracted from the job post. \\nMoreover, you can use a tool for getting a current tailored section.\\n\\nAlways split the response to the two parts in this format:\\n{\\n    \"response\": \"The response that will be showed to the user.\",\\n    \"tailored_section\": \"If change is required, the newly tailored section. Can be empty string if no update is required.\"\\n}\\n\\n-------------------------------\\n\\nOriginal Section:\\n## Applied Machine Learning Scientist \\n\\nNov. 2016 - Feb. 2019\\n\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\n- Highlighted projects: \\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\\n\\n-------------------------------\\n\\nJob Requirements:\\n**Required Qualifications:**\\n1. Bachelor\\'s degree or equivalent practical experience.\\n2. 2 years of experience with software development in one or more programming languages, and with data structures or algorithms.\\n3. 2 years of experience with machine learning algorithms and tools (e.g., TensorFlow), artificial intelligence, deep learning, or natural language processing.\\n4. Experience with Large Language Models, NLP, or Generative AI.\\n5. Experience with Coding, Experiment Design, Data Analysis.\\n6. Experience with recommendation systems/rankings/predictions.\\n\\n**Preferred Qualifications:**\\n1. Master\\'s degree or PhD in Computer Science or related technical fields.\\n2. Experience developing accessible technologies.\\n3. Experience with C++, Statistical Analysis, Python.\\n4. Experience with quality work in either serving quality or data quality.\\n5. Experience as a data analyst/scientist.\\n6. Experience in understanding user behavior (i.e., mathematical modeling or social science background).\\n\\n**Key Technical Skills:**\\n1. Programming languages (specific languages not mentioned, but implied).\\n2. Machine learning algorithms and tools (e.g., TensorFlow).\\n3. Large Language Models, NLP, or Generative AI.\\n4. C++, Statistical Analysis, Python.\\n5. Data structures and algorithms.\\n6. Experiment Design.\\n7. Data Analysis.\\n8. Recommendation systems/rankings/predictions.\\n\\n**Soft Skills:**\\n1. Versatility.\\n2. Leadership qualities.\\n3. Enthusiasm to take on new problems.\\n\\n**Education Requirements:**\\n1. Bachelor\\'s degree or equivalent practical experience (required).\\n2. Master\\'s degree or PhD in Computer Science or related technical fields (preferred).\\n\\n**Experience Level:**\\n1. Minimum of 2 years of experience in software development and machine learning (required).\\n2. Additional experience in data analysis, recommendation systems, and understanding user behavior is preferred.\\n\\n**Industry-Specific Keywords:**\\n1. Software engineering.\\n2. Artificial intelligence.\\n3. Natural language processing.\\n4. Large-scale system design.\\n5. E-commerce.\\n6. User experience (UX).\\n7. Digital world.\\n\\n**Responsibilities and Duties:**\\n1. Work in coding, modeling, and analysis.\\n2. Identify or create relevant signals for modeling.\\n3. Combine signals into a model for offline evaluation.\\n4. Integrate models into the production stack (e.g., search and shopping) and initiate live experiments.\\n\\n**Company Values or Culture Fit:**\\n1. Commitment to equal employment opportunity and diversity.\\n2. Emphasis on innovation and fresh ideas.\\n3. Focus on collaboration with the commerce ecosystem.\\n4. Support for both large retailers and small local merchants.\\n\\n'),\n",
       " HumanMessage(content='Can you tell me what the original section is?'),\n",
       " AIMessage(content='{\\n    \"response\": \"The original section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes your experience from November 2016 to February 2019. It details your work on recommender systems, data processing and analysis, collaboration with ML engineering teams, and highlights various projects related to model improvement, recommendation diversification, hyperparameter optimization, offline evaluation frameworks, A/B/n test evaluation, production implementation, and contextual bandits research.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('1233'), 'completion_tokens': Decimal('99'), 'prompt_tokens': Decimal('1134'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-d9642683-a937-43c7-b17f-7f67afc21796-0', usage_metadata={'input_tokens': 1134, 'output_tokens': 99, 'total_tokens': 1233}),\n",
       " HumanMessage(content='Can you tell me what the tailored section is?'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None, 'tool_calls': [{'type': 'function', 'id': 'call_Ib9rUb3u7bCK4HobUTFkvjRr', 'function': {'name': 'get_current_tailored_section', 'arguments': '{}'}}]}, response_metadata={'token_usage': {'total_tokens': Decimal('1263'), 'completion_tokens': Decimal('13'), 'prompt_tokens': Decimal('1250'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-fe8cd5bf-7cd3-42ba-9bb3-f3fb4c886f67-0', tool_calls=[{'name': 'get_current_tailored_section', 'args': {}, 'id': 'call_Ib9rUb3u7bCK4HobUTFkvjRr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1250, 'output_tokens': 13, 'total_tokens': 1263}),\n",
       " ToolMessage(content='\\n**Applied Machine Learning Scientist**  \\n*Nov. 2016 - Feb. 2019*\\n\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\n  \\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\n\\n- **Model Optimization and Evaluation:** \\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\n\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\\n', name='get_current_tailored_section', tool_call_id='call_Ib9rUb3u7bCK4HobUTFkvjRr'),\n",
       " AIMessage(content='{\\n    \"response\": \"The tailored section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes your experience from November 2016 to February 2019. It highlights your work on recommender systems, data processing and analysis, model optimization and evaluation, as well as research and collaboration. The section emphasizes your achievements and the tools you used, aligning closely with the job requirements.\",\\n    \"tailored_section\": \"**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*  \\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.  \\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.  \\\\n  \\\\n- **Model Optimization and Evaluation:**   \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.  \\\\n  \\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('1907'), 'completion_tokens': Decimal('375'), 'prompt_tokens': Decimal('1532'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-ad0e7dfb-0edf-414a-94d6-d2c19e6ff345-0', usage_metadata={'input_tokens': 1532, 'output_tokens': 375, 'total_tokens': 1907}),\n",
       " HumanMessage(content='I forgot to mention that I co-authored a workshop on the recommendation systems at the conference ML Prague. Can you include that?'),\n",
       " AIMessage(content='{\\n    \"response\": \"I can certainly include your co-authorship of the workshop on recommendation systems at the ML Prague conference. This will enhance your experience and showcase your involvement in the field. Let me update the tailored section accordingly.\",\\n    \"tailored_section\": \"**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*  \\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.  \\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.  \\\\n  \\\\n- **Model Optimization and Evaluation:**   \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.  \\\\n  \\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Co-authored a workshop on recommendation systems at the ML Prague conference. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2297'), 'completion_tokens': Decimal('357'), 'prompt_tokens': Decimal('1940'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-d562cd00-673c-4f82-b1db-b586c4df753b-0', usage_metadata={'input_tokens': 1940, 'output_tokens': 357, 'total_tokens': 2297}),\n",
       " HumanMessage(content='Can you make tailored section even more concise?'),\n",
       " AIMessage(content='{\\n    \"response\": \"I can definitely make the tailored section more concise while still highlighting your key achievements and experiences. Heres a more streamlined version.\",\\n    \"tailored_section\": \"**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*  \\\\n\\\\n- **Recommender Systems Development:** Developed collaborative filtering and online ML systems for lifestyle, news, and video content, achieving a double-digit increase in key metrics and reaching over half of the Czech internet population.  \\\\n  \\\\n- **Data Processing:** Analyzed terabytes of logs daily using PySpark, creating a proprietary framework for data manipulation and quality assurance.  \\\\n  \\\\n- **Model Optimization:** Enhanced online ML models through data cleaning and feature engineering. Developed an offline evaluation framework and coauthored an A/B/n test evaluation library.  \\\\n  \\\\n- **Research and Collaboration:** Researched contextual bandits, leading to a publication at SIGIR 2019 and co-authored a workshop on recommendation systems at ML Prague. Collaborated with ML engineering teams to ensure code quality and successful production transitions.\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2548'), 'completion_tokens': Decimal('235'), 'prompt_tokens': Decimal('2313'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-998d3554-a280-4374-aa87-edd69b698b3f-0', usage_metadata={'input_tokens': 2313, 'output_tokens': 235, 'total_tokens': 2548})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = get_message_history(conversation_id=conversation_id).messages\n",
    "messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
