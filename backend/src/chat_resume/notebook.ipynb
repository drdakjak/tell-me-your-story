{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from handler import handler, get_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_response(response):\n",
    "    response = json.loads(response['body'])\n",
    "    print('Response')\n",
    "    display(Markdown(response['response']))\n",
    "    print('Tailored Section')\n",
    "    display(Markdown(response['tailored_section']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Applied Machine Learning Scientist \n",
       "\n",
       "Nov. 2016 - Feb. 2019\n",
       "\n",
       "- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \n",
       "- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \n",
       "- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \n",
       "- Highlighted projects: \n",
       "    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \n",
       "    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \n",
       "    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \n",
       "    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \n",
       "    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \n",
       "    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \n",
       "    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_section = \"## Applied Machine Learning Scientist \\n\\nNov. 2016 - Feb. 2019\\n\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\n- Highlighted projects: \\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\"\n",
    "display(Markdown(original_section))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Applied Machine Learning Scientist**  \n",
       "*Nov. 2016 - Feb. 2019*\n",
       "\n",
       "- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\n",
       "  \n",
       "- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\n",
       "\n",
       "- **Model Optimization and Evaluation:** \n",
       "  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\n",
       "  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\n",
       "  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\n",
       "\n",
       "- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tailored_section = '\\n**Applied Machine Learning Scientist**  \\n*Nov. 2016 - Feb. 2019*\\n\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\n  \\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\n\\n- **Model Optimization and Evaluation:** \\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\n\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\\n'\n",
    "display(Markdown(tailored_section))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event(file_name):\n",
    "    path = f\"events/{file_name}\"\n",
    "    with open(path, 'r') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_1 = get_event(\"event_1.json\")\n",
    "conversation_id = event_1['body']['conversation_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You\\'re an expert resume writer. \\n\\n1. Help tailor this resume section to match job requirements.\\n2. Comunicate with the user to understand their needs.\\n3. Ask for clarification if needed. \\n\\nYou have access to the Original Section of the resume and the Job Requirements extracted from the job post. \\nMoreover, you can use a tool for getting a tailored section.\\n\\nAlways split the response to the two parts in this format:\\n{\\n    \"response\": \"The response that will be showed to the user.\",\\n    \"tailored_section\": \"If change is required, the newly tailored section. Can be empty string if no update is required.\"\\n}\\n\\n-------------------------------\\n\\nOriginal Section:\\n## Applied Machine Learning Scientist \\n\\nNov. 2016 - Feb. 2019\\n\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\n- Highlighted projects: \\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\\n\\n-------------------------------\\n\\nJob Requirements:\\n**Required Qualifications:**\\n1. Bachelor\\'s degree or equivalent practical experience.\\n2. 2 years of experience with software development in one or more programming languages, and with data structures or algorithms.\\n3. 2 years of experience with machine learning algorithms and tools (e.g., TensorFlow), artificial intelligence, deep learning, or natural language processing.\\n4. Experience with Large Language Models, NLP, or Generative AI.\\n5. Experience with Coding, Experiment Design, Data Analysis.\\n6. Experience with recommendation systems/rankings/predictions.\\n\\n**Preferred Qualifications:**\\n1. Master\\'s degree or PhD in Computer Science or related technical fields.\\n2. Experience developing accessible technologies.\\n3. Experience with C++, Statistical Analysis, Python.\\n4. Experience with quality work in either serving quality or data quality.\\n5. Experience as a data analyst/scientist.\\n6. Experience in understanding user behavior (i.e., mathematical modeling or social science background).\\n\\n**Key Technical Skills:**\\n1. Programming languages (specific languages not mentioned, but implied).\\n2. Machine learning algorithms and tools (e.g., TensorFlow).\\n3. Large Language Models, NLP, or Generative AI.\\n4. C++.\\n5. Statistical Analysis.\\n6. Python.\\n7. Data Analysis.\\n8. Experiment Design.\\n9. Recommendation systems/rankings/predictions.\\n\\n**Soft Skills:**\\n1. Versatility.\\n2. Leadership qualities.\\n3. Enthusiasm to take on new problems.\\n\\n**Education Requirements:**\\n1. Bachelor\\'s degree or equivalent practical experience (required).\\n2. Master\\'s degree or PhD in Computer Science or related technical fields (preferred).\\n\\n**Experience Level:**\\n- Minimum of 2 years of experience in software development and machine learning (required).\\n\\n**Industry-Specific Keywords:**\\n1. Software engineering.\\n2. Artificial intelligence.\\n3. Natural language processing.\\n4. Large-scale system design.\\n5. E-commerce.\\n6. User behavior modeling.\\n\\n**Responsibilities and Duties:**\\n1. Work in coding, modeling, and analysis.\\n2. Find or create the right signals for modeling.\\n3. Combine signals into a model and evaluate its merit through offline evaluation.\\n4. Integrate models into the production stack (e.g., search and shopping) and initiate live experiments.\\n\\n**Company Values or Culture Fit:**\\n- Commitment to equal employment opportunity and diversity.\\n- Emphasis on innovation and versatility in problem-solving.\\n- Focus on collaboration with the commerce ecosystem to enhance user experiences.\\n\\n'),\n",
       " HumanMessage(content='Can you tell me what the original section is?'),\n",
       " AIMessage(content='{\\n    \"response\": \"The original section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes the following details:\\\\n\\\\n## Applied Machine Learning Scientist \\\\n\\\\nNov. 2016 - Feb. 2019\\\\n\\\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\\\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\\\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\\\n- Highlighted projects: \\\\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\\\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\\\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\\\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\\\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\\\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\\\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('1564'), 'completion_tokens': Decimal('462'), 'prompt_tokens': Decimal('1102'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-8c9d3a1d-5048-406c-80f9-9f8ca059130d-0', usage_metadata={'input_tokens': 1102, 'output_tokens': 462, 'total_tokens': 1564}),\n",
       " HumanMessage(content='Can you tell me what the tailored section is?'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None, 'tool_calls': [{'type': 'function', 'id': 'call_JRHO6M7sEeZcbcdsMahN8P0L', 'function': {'name': 'get_current_tailored_section', 'arguments': '{}'}}]}, response_metadata={'token_usage': {'total_tokens': Decimal('1594'), 'completion_tokens': Decimal('13'), 'prompt_tokens': Decimal('1581'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-0949efe8-5569-4026-a361-a6040df6585f-0', tool_calls=[{'name': 'get_current_tailored_section', 'args': {}, 'id': 'call_JRHO6M7sEeZcbcdsMahN8P0L', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1581, 'output_tokens': 13, 'total_tokens': 1594}),\n",
       " ToolMessage(content='\\n**Applied Machine Learning Scientist**  \\n*Nov. 2016 - Feb. 2019*\\n\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\n  \\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\n\\n- **Model Optimization and Evaluation:** \\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\n\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\\n', name='get_current_tailored_section', tool_call_id='call_JRHO6M7sEeZcbcdsMahN8P0L'),\n",
       " AIMessage(content='{\\n    \"response\": \"The tailored section of your resume is as follows:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2166'), 'completion_tokens': Decimal('303'), 'prompt_tokens': Decimal('1863'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-1b19a4d6-5f70-4e61-b8c8-d0692ba36ca1-0', usage_metadata={'input_tokens': 1863, 'output_tokens': 303, 'total_tokens': 2166}),\n",
       " HumanMessage(content='I forgot to mention that I co-authored a workshop on the recommendation systems at the conference ML Prague. Can you include that?'),\n",
       " AIMessage(content='{\\n    \"response\": \"Thank you for the additional information! I will include your co-authorship of the workshop on recommendation systems at the ML Prague conference in the tailored section. Here’s the updated version:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Co-authored a workshop on recommendation systems at the ML Prague conference. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\",\\n    \"tailored_section\": \"Co-authored a workshop on recommendation systems at the ML Prague conference.\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2556'), 'completion_tokens': Decimal('357'), 'prompt_tokens': Decimal('2199'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-74b4d994-112f-4bd1-9832-571ef37f94ff-0', usage_metadata={'input_tokens': 2199, 'output_tokens': 357, 'total_tokens': 2556}),\n",
       " HumanMessage(content='Can you make tailored section even more concise?'),\n",
       " AIMessage(content='{\\n    \"response\": \"Sure! Here’s a more concise version of the tailored section:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Developed collaborative filtering and online ML systems for lifestyle, news, and video content, achieving a double-digit increase in key metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Analyzed terabytes of logs daily using PySpark, creating a proprietary framework for data manipulation and quality checks.\\\\n\\\\n- **Model Optimization:**  \\\\n  - Enhanced online ML models through data cleaning and feature engineering, utilizing Vowpal Wabbit and Python.  \\\\n  - Developed an offline evaluation framework based on matrix factorization to inform deployment decisions.  \\\\n  - Coauthored a library for A/B/n test evaluation to optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, leading to a publication at SIGIR 2019 and co-authoring a workshop on recommendation systems at ML Prague. Collaborated with ML engineering teams to transition prototypes to production, ensuring code quality through reviews.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2831'), 'completion_tokens': Decimal('259'), 'prompt_tokens': Decimal('2572'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-6ce76a4a-5472-47e8-a803-3af9af01de01-0', usage_metadata={'input_tokens': 2572, 'output_tokens': 259, 'total_tokens': 2831}),\n",
       " HumanMessage(content='Can you tell me what the original section is?'),\n",
       " AIMessage(content='{\\n    \"response\": \"The original section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes the following details:\\\\n\\\\n## Applied Machine Learning Scientist \\\\n\\\\nNov. 2016 - Feb. 2019\\\\n\\\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\\\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\\\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\\\n- Highlighted projects: \\\\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\\\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\\\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\\\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\\\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\\\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\\\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('3310'), 'completion_tokens': Decimal('462'), 'prompt_tokens': Decimal('2848'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-b33fddf1-d6c1-4b65-beb2-86a27bfa3226-0', usage_metadata={'input_tokens': 2848, 'output_tokens': 462, 'total_tokens': 3310})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_message_history(conversation_id=conversation_id).messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The original section of your resume is titled 'Applied Machine Learning Scientist' and includes the following details:\n",
       "\n",
       "## Applied Machine Learning Scientist \n",
       "\n",
       "Nov. 2016 - Feb. 2019\n",
       "\n",
       "- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \n",
       "- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \n",
       "- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \n",
       "- Highlighted projects: \n",
       "    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \n",
       "    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \n",
       "    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \n",
       "    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \n",
       "    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \n",
       "    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \n",
       "    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tailored Section\n"
     ]
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = handler(event_1, None)\n",
    "format_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The original section of your resume is titled 'Applied Machine Learning Scientist' and includes the following details:\n",
       "\n",
       "## Applied Machine Learning Scientist \n",
       "\n",
       "Nov. 2016 - Feb. 2019\n",
       "\n",
       "- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \n",
       "- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \n",
       "- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \n",
       "- Highlighted projects: \n",
       "    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \n",
       "    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \n",
       "    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \n",
       "    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \n",
       "    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \n",
       "    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \n",
       "    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tailored Section\n"
     ]
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "format_response(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You\\'re an expert resume writer. \\n\\n1. Help tailor this resume section to match job requirements.\\n2. Comunicate with the user to understand their needs.\\n3. Ask for clarification if needed. \\n\\nYou have access to the Original Section of the resume and the Job Requirements extracted from the job post. \\nMoreover, you can use a tool for getting a tailored section.\\n\\nAlways split the response to the two parts in this format:\\n{\\n    \"response\": \"The response that will be showed to the user.\",\\n    \"tailored_section\": \"If change is required, the newly tailored section. Can be empty string if no update is required.\"\\n}\\n\\n-------------------------------\\n\\nOriginal Section:\\n## Applied Machine Learning Scientist \\n\\nNov. 2016 - Feb. 2019\\n\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\n- Highlighted projects: \\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\\n\\n-------------------------------\\n\\nJob Requirements:\\n**Required Qualifications:**\\n1. Bachelor\\'s degree or equivalent practical experience.\\n2. 2 years of experience with software development in one or more programming languages, and with data structures or algorithms.\\n3. 2 years of experience with machine learning algorithms and tools (e.g., TensorFlow), artificial intelligence, deep learning, or natural language processing.\\n4. Experience with Large Language Models, NLP, or Generative AI.\\n5. Experience with Coding, Experiment Design, Data Analysis.\\n6. Experience with recommendation systems/rankings/predictions.\\n\\n**Preferred Qualifications:**\\n1. Master\\'s degree or PhD in Computer Science or related technical fields.\\n2. Experience developing accessible technologies.\\n3. Experience with C++, Statistical Analysis, Python.\\n4. Experience with quality work in either serving quality or data quality.\\n5. Experience as a data analyst/scientist.\\n6. Experience in understanding user behavior (i.e., mathematical modeling or social science background).\\n\\n**Key Technical Skills:**\\n1. Programming languages (specific languages not mentioned, but implied).\\n2. Machine learning algorithms and tools (e.g., TensorFlow).\\n3. Large Language Models, NLP, or Generative AI.\\n4. C++.\\n5. Statistical Analysis.\\n6. Python.\\n7. Data Analysis.\\n8. Experiment Design.\\n9. Recommendation systems/rankings/predictions.\\n\\n**Soft Skills:**\\n1. Versatility.\\n2. Leadership qualities.\\n3. Enthusiasm to take on new problems.\\n\\n**Education Requirements:**\\n1. Bachelor\\'s degree or equivalent practical experience (required).\\n2. Master\\'s degree or PhD in Computer Science or related technical fields (preferred).\\n\\n**Experience Level:**\\n- Minimum of 2 years of experience in software development and machine learning (required).\\n\\n**Industry-Specific Keywords:**\\n1. Software engineering.\\n2. Artificial intelligence.\\n3. Natural language processing.\\n4. Large-scale system design.\\n5. E-commerce.\\n6. User behavior modeling.\\n\\n**Responsibilities and Duties:**\\n1. Work in coding, modeling, and analysis.\\n2. Find or create the right signals for modeling.\\n3. Combine signals into a model and evaluate its merit through offline evaluation.\\n4. Integrate models into the production stack (e.g., search and shopping) and initiate live experiments.\\n\\n**Company Values or Culture Fit:**\\n- Commitment to equal employment opportunity and diversity.\\n- Emphasis on innovation and versatility in problem-solving.\\n- Focus on collaboration with the commerce ecosystem to enhance user experiences.\\n\\n'),\n",
       " HumanMessage(content='Can you tell me what the original section is?'),\n",
       " AIMessage(content='{\\n    \"response\": \"The original section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes the following details:\\\\n\\\\n## Applied Machine Learning Scientist \\\\n\\\\nNov. 2016 - Feb. 2019\\\\n\\\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\\\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\\\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\\\n- Highlighted projects: \\\\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\\\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\\\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\\\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\\\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\\\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\\\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('1564'), 'completion_tokens': Decimal('462'), 'prompt_tokens': Decimal('1102'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-8c9d3a1d-5048-406c-80f9-9f8ca059130d-0', usage_metadata={'input_tokens': 1102, 'output_tokens': 462, 'total_tokens': 1564}),\n",
       " HumanMessage(content='Can you tell me what the tailored section is?'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None, 'tool_calls': [{'type': 'function', 'id': 'call_JRHO6M7sEeZcbcdsMahN8P0L', 'function': {'name': 'get_current_tailored_section', 'arguments': '{}'}}]}, response_metadata={'token_usage': {'total_tokens': Decimal('1594'), 'completion_tokens': Decimal('13'), 'prompt_tokens': Decimal('1581'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-0949efe8-5569-4026-a361-a6040df6585f-0', tool_calls=[{'name': 'get_current_tailored_section', 'args': {}, 'id': 'call_JRHO6M7sEeZcbcdsMahN8P0L', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1581, 'output_tokens': 13, 'total_tokens': 1594}),\n",
       " ToolMessage(content='\\n**Applied Machine Learning Scientist**  \\n*Nov. 2016 - Feb. 2019*\\n\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\n  \\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\n\\n- **Model Optimization and Evaluation:** \\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\n\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\\n', name='get_current_tailored_section', tool_call_id='call_JRHO6M7sEeZcbcdsMahN8P0L'),\n",
       " AIMessage(content='{\\n    \"response\": \"The tailored section of your resume is as follows:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2166'), 'completion_tokens': Decimal('303'), 'prompt_tokens': Decimal('1863'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-1b19a4d6-5f70-4e61-b8c8-d0692ba36ca1-0', usage_metadata={'input_tokens': 1863, 'output_tokens': 303, 'total_tokens': 2166}),\n",
       " HumanMessage(content='I forgot to mention that I co-authored a workshop on the recommendation systems at the conference ML Prague. Can you include that?'),\n",
       " AIMessage(content='{\\n    \"response\": \"Thank you for the additional information! I will include your co-authorship of the workshop on recommendation systems at the ML Prague conference in the tailored section. Here’s the updated version:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Co-authored a workshop on recommendation systems at the ML Prague conference. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\",\\n    \"tailored_section\": \"Co-authored a workshop on recommendation systems at the ML Prague conference.\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2556'), 'completion_tokens': Decimal('357'), 'prompt_tokens': Decimal('2199'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-74b4d994-112f-4bd1-9832-571ef37f94ff-0', usage_metadata={'input_tokens': 2199, 'output_tokens': 357, 'total_tokens': 2556}),\n",
       " HumanMessage(content='Can you make tailored section even more concise?'),\n",
       " AIMessage(content='{\\n    \"response\": \"Sure! Here’s a more concise version of the tailored section:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Developed collaborative filtering and online ML systems for lifestyle, news, and video content, achieving a double-digit increase in key metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Analyzed terabytes of logs daily using PySpark, creating a proprietary framework for data manipulation and quality checks.\\\\n\\\\n- **Model Optimization:**  \\\\n  - Enhanced online ML models through data cleaning and feature engineering, utilizing Vowpal Wabbit and Python.  \\\\n  - Developed an offline evaluation framework based on matrix factorization to inform deployment decisions.  \\\\n  - Coauthored a library for A/B/n test evaluation to optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, leading to a publication at SIGIR 2019 and co-authoring a workshop on recommendation systems at ML Prague. Collaborated with ML engineering teams to transition prototypes to production, ensuring code quality through reviews.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2831'), 'completion_tokens': Decimal('259'), 'prompt_tokens': Decimal('2572'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-6ce76a4a-5472-47e8-a803-3af9af01de01-0', usage_metadata={'input_tokens': 2572, 'output_tokens': 259, 'total_tokens': 2831}),\n",
       " HumanMessage(content='Can you tell me what the original section is?'),\n",
       " AIMessage(content='{\\n    \"response\": \"The original section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes the following details:\\\\n\\\\n## Applied Machine Learning Scientist \\\\n\\\\nNov. 2016 - Feb. 2019\\\\n\\\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\\\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\\\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\\\n- Highlighted projects: \\\\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\\\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\\\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\\\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\\\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\\\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\\\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('3310'), 'completion_tokens': Decimal('462'), 'prompt_tokens': Decimal('2848'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-b33fddf1-d6c1-4b65-beb2-86a27bfa3226-0', usage_metadata={'input_tokens': 2848, 'output_tokens': 462, 'total_tokens': 3310}),\n",
       " HumanMessage(content='Can you tell me what the original section is?'),\n",
       " AIMessage(content='{\\n    \"response\": \"The original section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes the following details:\\\\n\\\\n## Applied Machine Learning Scientist \\\\n\\\\nNov. 2016 - Feb. 2019\\\\n\\\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\\\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\\\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\\\n- Highlighted projects: \\\\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\\\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\\\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\\\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\\\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\\\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\\\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('3789'), 'completion_tokens': Decimal('462'), 'prompt_tokens': Decimal('3327'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-c9299fd2-f72b-48fc-a4db-f4a7d76f5881-0', usage_metadata={'input_tokens': 3327, 'output_tokens': 462, 'total_tokens': 3789})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_message_history(conversation_id=conversation_id).messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_2 = get_event(\"event_2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The tailored section of your resume is as follows:\n",
       "\n",
       "**Applied Machine Learning Scientist**  \n",
       "*Nov. 2016 - Feb. 2019*\n",
       "\n",
       "- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\n",
       "  \n",
       "- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\n",
       "\n",
       "- **Model Optimization and Evaluation:**  \n",
       "  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \n",
       "  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \n",
       "  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\n",
       "\n",
       "- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tailored Section\n"
     ]
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = handler(event_2, None)\n",
    "format_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You\\'re an expert resume writer. \\n\\n1. Help tailor this resume section to match job requirements.\\n2. Comunicate with the user to understand their needs.\\n3. Ask for clarification if needed. \\n\\nYou have access to the Original Section of the resume and the Job Requirements extracted from the job post. \\nMoreover, you can use a tool for getting a tailored section.\\n\\nAlways split the response to the two parts in this format:\\n{\\n    \"response\": \"The response that will be showed to the user.\",\\n    \"tailored_section\": \"If change is required, the newly tailored section. Can be empty string if no update is required.\"\\n}\\n\\n-------------------------------\\n\\nOriginal Section:\\n## Applied Machine Learning Scientist \\n\\nNov. 2016 - Feb. 2019\\n\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\n- Highlighted projects: \\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\\n\\n-------------------------------\\n\\nJob Requirements:\\n**Required Qualifications:**\\n1. Bachelor\\'s degree or equivalent practical experience.\\n2. 2 years of experience with software development in one or more programming languages, and with data structures or algorithms.\\n3. 2 years of experience with machine learning algorithms and tools (e.g., TensorFlow), artificial intelligence, deep learning, or natural language processing.\\n4. Experience with Large Language Models, NLP, or Generative AI.\\n5. Experience with Coding, Experiment Design, Data Analysis.\\n6. Experience with recommendation systems/rankings/predictions.\\n\\n**Preferred Qualifications:**\\n1. Master\\'s degree or PhD in Computer Science or related technical fields.\\n2. Experience developing accessible technologies.\\n3. Experience with C++, Statistical Analysis, Python.\\n4. Experience with quality work in either serving quality or data quality.\\n5. Experience as a data analyst/scientist.\\n6. Experience in understanding user behavior (i.e., mathematical modeling or social science background).\\n\\n**Key Technical Skills:**\\n1. Programming languages (specific languages not mentioned, but implied).\\n2. Machine learning algorithms and tools (e.g., TensorFlow).\\n3. Large Language Models, NLP, or Generative AI.\\n4. C++.\\n5. Statistical Analysis.\\n6. Python.\\n7. Data Analysis.\\n8. Experiment Design.\\n9. Recommendation systems/rankings/predictions.\\n\\n**Soft Skills:**\\n1. Versatility.\\n2. Leadership qualities.\\n3. Enthusiasm to take on new problems.\\n\\n**Education Requirements:**\\n1. Bachelor\\'s degree or equivalent practical experience (required).\\n2. Master\\'s degree or PhD in Computer Science or related technical fields (preferred).\\n\\n**Experience Level:**\\n- Minimum of 2 years of experience in software development and machine learning (required).\\n\\n**Industry-Specific Keywords:**\\n1. Software engineering.\\n2. Artificial intelligence.\\n3. Natural language processing.\\n4. Large-scale system design.\\n5. E-commerce.\\n6. User behavior modeling.\\n\\n**Responsibilities and Duties:**\\n1. Work in coding, modeling, and analysis.\\n2. Find or create the right signals for modeling.\\n3. Combine signals into a model and evaluate its merit through offline evaluation.\\n4. Integrate models into the production stack (e.g., search and shopping) and initiate live experiments.\\n\\n**Company Values or Culture Fit:**\\n- Commitment to equal employment opportunity and diversity.\\n- Emphasis on innovation and versatility in problem-solving.\\n- Focus on collaboration with the commerce ecosystem to enhance user experiences.\\n\\n'),\n",
       " HumanMessage(content='Can you tell me what the original section is?'),\n",
       " AIMessage(content='{\\n    \"response\": \"The original section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes the following details:\\\\n\\\\n## Applied Machine Learning Scientist \\\\n\\\\nNov. 2016 - Feb. 2019\\\\n\\\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\\\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\\\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\\\n- Highlighted projects: \\\\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\\\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\\\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\\\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\\\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\\\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\\\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('1564'), 'completion_tokens': Decimal('462'), 'prompt_tokens': Decimal('1102'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-8c9d3a1d-5048-406c-80f9-9f8ca059130d-0', usage_metadata={'input_tokens': 1102, 'output_tokens': 462, 'total_tokens': 1564}),\n",
       " HumanMessage(content='Can you tell me what the tailored section is?'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None, 'tool_calls': [{'type': 'function', 'id': 'call_JRHO6M7sEeZcbcdsMahN8P0L', 'function': {'name': 'get_current_tailored_section', 'arguments': '{}'}}]}, response_metadata={'token_usage': {'total_tokens': Decimal('1594'), 'completion_tokens': Decimal('13'), 'prompt_tokens': Decimal('1581'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-0949efe8-5569-4026-a361-a6040df6585f-0', tool_calls=[{'name': 'get_current_tailored_section', 'args': {}, 'id': 'call_JRHO6M7sEeZcbcdsMahN8P0L', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1581, 'output_tokens': 13, 'total_tokens': 1594}),\n",
       " ToolMessage(content='\\n**Applied Machine Learning Scientist**  \\n*Nov. 2016 - Feb. 2019*\\n\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\n  \\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\n\\n- **Model Optimization and Evaluation:** \\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\n\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\\n', name='get_current_tailored_section', tool_call_id='call_JRHO6M7sEeZcbcdsMahN8P0L'),\n",
       " AIMessage(content='{\\n    \"response\": \"The tailored section of your resume is as follows:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2166'), 'completion_tokens': Decimal('303'), 'prompt_tokens': Decimal('1863'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-1b19a4d6-5f70-4e61-b8c8-d0692ba36ca1-0', usage_metadata={'input_tokens': 1863, 'output_tokens': 303, 'total_tokens': 2166}),\n",
       " HumanMessage(content='I forgot to mention that I co-authored a workshop on the recommendation systems at the conference ML Prague. Can you include that?'),\n",
       " AIMessage(content='{\\n    \"response\": \"Thank you for the additional information! I will include your co-authorship of the workshop on recommendation systems at the ML Prague conference in the tailored section. Here’s the updated version:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Co-authored a workshop on recommendation systems at the ML Prague conference. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\",\\n    \"tailored_section\": \"Co-authored a workshop on recommendation systems at the ML Prague conference.\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2556'), 'completion_tokens': Decimal('357'), 'prompt_tokens': Decimal('2199'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-74b4d994-112f-4bd1-9832-571ef37f94ff-0', usage_metadata={'input_tokens': 2199, 'output_tokens': 357, 'total_tokens': 2556}),\n",
       " HumanMessage(content='Can you make tailored section even more concise?'),\n",
       " AIMessage(content='{\\n    \"response\": \"Sure! Here’s a more concise version of the tailored section:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Developed collaborative filtering and online ML systems for lifestyle, news, and video content, achieving a double-digit increase in key metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Analyzed terabytes of logs daily using PySpark, creating a proprietary framework for data manipulation and quality checks.\\\\n\\\\n- **Model Optimization:**  \\\\n  - Enhanced online ML models through data cleaning and feature engineering, utilizing Vowpal Wabbit and Python.  \\\\n  - Developed an offline evaluation framework based on matrix factorization to inform deployment decisions.  \\\\n  - Coauthored a library for A/B/n test evaluation to optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, leading to a publication at SIGIR 2019 and co-authoring a workshop on recommendation systems at ML Prague. Collaborated with ML engineering teams to transition prototypes to production, ensuring code quality through reviews.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2831'), 'completion_tokens': Decimal('259'), 'prompt_tokens': Decimal('2572'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-6ce76a4a-5472-47e8-a803-3af9af01de01-0', usage_metadata={'input_tokens': 2572, 'output_tokens': 259, 'total_tokens': 2831}),\n",
       " HumanMessage(content='Can you tell me what the original section is?'),\n",
       " AIMessage(content='{\\n    \"response\": \"The original section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes the following details:\\\\n\\\\n## Applied Machine Learning Scientist \\\\n\\\\nNov. 2016 - Feb. 2019\\\\n\\\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\\\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\\\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\\\n- Highlighted projects: \\\\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\\\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\\\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\\\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\\\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\\\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\\\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('3310'), 'completion_tokens': Decimal('462'), 'prompt_tokens': Decimal('2848'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-b33fddf1-d6c1-4b65-beb2-86a27bfa3226-0', usage_metadata={'input_tokens': 2848, 'output_tokens': 462, 'total_tokens': 3310}),\n",
       " HumanMessage(content='Can you tell me what the original section is?'),\n",
       " AIMessage(content='{\\n    \"response\": \"The original section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes the following details:\\\\n\\\\n## Applied Machine Learning Scientist \\\\n\\\\nNov. 2016 - Feb. 2019\\\\n\\\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\\\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\\\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\\\n- Highlighted projects: \\\\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\\\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\\\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\\\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\\\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\\\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\\\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('3789'), 'completion_tokens': Decimal('462'), 'prompt_tokens': Decimal('3327'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-c9299fd2-f72b-48fc-a4db-f4a7d76f5881-0', usage_metadata={'input_tokens': 3327, 'output_tokens': 462, 'total_tokens': 3789}),\n",
       " HumanMessage(content='Can you tell me what the tailored section is?'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None, 'tool_calls': [{'type': 'function', 'id': 'call_Eplgm9ZTwwK9QU3btFMUc7Tp', 'function': {'name': 'get_current_tailored_section', 'arguments': '{}'}}]}, response_metadata={'token_usage': {'total_tokens': Decimal('3819'), 'completion_tokens': Decimal('13'), 'prompt_tokens': Decimal('3806'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-f81234fc-78e0-4459-b151-a8fb0739366f-0', tool_calls=[{'name': 'get_current_tailored_section', 'args': {}, 'id': 'call_Eplgm9ZTwwK9QU3btFMUc7Tp', 'type': 'tool_call'}], usage_metadata={'input_tokens': 3806, 'output_tokens': 13, 'total_tokens': 3819}),\n",
       " ToolMessage(content='\\n**Applied Machine Learning Scientist**  \\n*Nov. 2016 - Feb. 2019*\\n\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\n  \\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\n\\n- **Model Optimization and Evaluation:** \\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\n\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\\n', name='get_current_tailored_section', tool_call_id='call_Eplgm9ZTwwK9QU3btFMUc7Tp'),\n",
       " AIMessage(content='{\\n    \"response\": \"The tailored section of your resume is as follows:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('4391'), 'completion_tokens': Decimal('303'), 'prompt_tokens': Decimal('4088'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-eb70382c-f97c-42d4-8a02-307694905681-0', usage_metadata={'input_tokens': 4088, 'output_tokens': 303, 'total_tokens': 4391})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_message_history(conversation_id=conversation_id).messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_3 = get_event(\"event_3.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Thank you for the additional information! I will include your co-authorship of the workshop on recommendation systems at the ML Prague conference in the tailored section. Here’s the updated version:\n",
       "\n",
       "**Applied Machine Learning Scientist**  \n",
       "*Nov. 2016 - Feb. 2019*\n",
       "\n",
       "- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\n",
       "  \n",
       "- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\n",
       "\n",
       "- **Model Optimization and Evaluation:**  \n",
       "  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \n",
       "  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \n",
       "  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\n",
       "\n",
       "- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Co-authored a workshop on recommendation systems at the ML Prague conference. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tailored Section\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Co-authored a workshop on recommendation systems at the ML Prague conference."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = handler(event_3, None)\n",
    "format_response(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You\\'re an expert resume writer. \\n\\n1. Help tailor this resume section to match job requirements.\\n2. Comunicate with the user to understand their needs.\\n3. Ask for clarification if needed. \\n\\nYou have access to the Original Section of the resume and the Job Requirements extracted from the job post. \\nMoreover, you can use a tool for getting a tailored section.\\n\\nAlways split the response to the two parts in this format:\\n{\\n    \"response\": \"The response that will be showed to the user.\",\\n    \"tailored_section\": \"If change is required, the newly tailored section. Can be empty string if no update is required.\"\\n}\\n\\n-------------------------------\\n\\nOriginal Section:\\n## Applied Machine Learning Scientist \\n\\nNov. 2016 - Feb. 2019\\n\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\n- Highlighted projects: \\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\\n\\n-------------------------------\\n\\nJob Requirements:\\n**Required Qualifications:**\\n1. Bachelor\\'s degree or equivalent practical experience.\\n2. 2 years of experience with software development in one or more programming languages, and with data structures or algorithms.\\n3. 2 years of experience with machine learning algorithms and tools (e.g., TensorFlow), artificial intelligence, deep learning, or natural language processing.\\n4. Experience with Large Language Models, NLP, or Generative AI.\\n5. Experience with Coding, Experiment Design, Data Analysis.\\n6. Experience with recommendation systems/rankings/predictions.\\n\\n**Preferred Qualifications:**\\n1. Master\\'s degree or PhD in Computer Science or related technical fields.\\n2. Experience developing accessible technologies.\\n3. Experience with C++, Statistical Analysis, Python.\\n4. Experience with quality work in either serving quality or data quality.\\n5. Experience as a data analyst/scientist.\\n6. Experience in understanding user behavior (i.e., mathematical modeling or social science background).\\n\\n**Key Technical Skills:**\\n1. Programming languages (specific languages not mentioned, but implied).\\n2. Machine learning algorithms and tools (e.g., TensorFlow).\\n3. Large Language Models, NLP, or Generative AI.\\n4. C++.\\n5. Statistical Analysis.\\n6. Python.\\n7. Data Analysis.\\n8. Experiment Design.\\n9. Recommendation systems/rankings/predictions.\\n\\n**Soft Skills:**\\n1. Versatility.\\n2. Leadership qualities.\\n3. Enthusiasm to take on new problems.\\n\\n**Education Requirements:**\\n1. Bachelor\\'s degree or equivalent practical experience (required).\\n2. Master\\'s degree or PhD in Computer Science or related technical fields (preferred).\\n\\n**Experience Level:**\\n- Minimum of 2 years of experience in software development and machine learning (required).\\n\\n**Industry-Specific Keywords:**\\n1. Software engineering.\\n2. Artificial intelligence.\\n3. Natural language processing.\\n4. Large-scale system design.\\n5. E-commerce.\\n6. User behavior modeling.\\n\\n**Responsibilities and Duties:**\\n1. Work in coding, modeling, and analysis.\\n2. Find or create the right signals for modeling.\\n3. Combine signals into a model and evaluate its merit through offline evaluation.\\n4. Integrate models into the production stack (e.g., search and shopping) and initiate live experiments.\\n\\n**Company Values or Culture Fit:**\\n- Commitment to equal employment opportunity and diversity.\\n- Emphasis on innovation and versatility in problem-solving.\\n- Focus on collaboration with the commerce ecosystem to enhance user experiences.\\n\\n'),\n",
       " HumanMessage(content='Can you tell me what the original section is?'),\n",
       " AIMessage(content='{\\n    \"response\": \"The original section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes the following details:\\\\n\\\\n## Applied Machine Learning Scientist \\\\n\\\\nNov. 2016 - Feb. 2019\\\\n\\\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\\\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\\\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\\\n- Highlighted projects: \\\\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\\\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\\\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\\\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\\\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\\\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\\\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('1564'), 'completion_tokens': Decimal('462'), 'prompt_tokens': Decimal('1102'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-8c9d3a1d-5048-406c-80f9-9f8ca059130d-0', usage_metadata={'input_tokens': 1102, 'output_tokens': 462, 'total_tokens': 1564}),\n",
       " HumanMessage(content='Can you tell me what the tailored section is?'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None, 'tool_calls': [{'type': 'function', 'id': 'call_JRHO6M7sEeZcbcdsMahN8P0L', 'function': {'name': 'get_current_tailored_section', 'arguments': '{}'}}]}, response_metadata={'token_usage': {'total_tokens': Decimal('1594'), 'completion_tokens': Decimal('13'), 'prompt_tokens': Decimal('1581'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-0949efe8-5569-4026-a361-a6040df6585f-0', tool_calls=[{'name': 'get_current_tailored_section', 'args': {}, 'id': 'call_JRHO6M7sEeZcbcdsMahN8P0L', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1581, 'output_tokens': 13, 'total_tokens': 1594}),\n",
       " ToolMessage(content='\\n**Applied Machine Learning Scientist**  \\n*Nov. 2016 - Feb. 2019*\\n\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\n  \\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\n\\n- **Model Optimization and Evaluation:** \\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\n\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\\n', name='get_current_tailored_section', tool_call_id='call_JRHO6M7sEeZcbcdsMahN8P0L'),\n",
       " AIMessage(content='{\\n    \"response\": \"The tailored section of your resume is as follows:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2166'), 'completion_tokens': Decimal('303'), 'prompt_tokens': Decimal('1863'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-1b19a4d6-5f70-4e61-b8c8-d0692ba36ca1-0', usage_metadata={'input_tokens': 1863, 'output_tokens': 303, 'total_tokens': 2166}),\n",
       " HumanMessage(content='I forgot to mention that I co-authored a workshop on the recommendation systems at the conference ML Prague. Can you include that?'),\n",
       " AIMessage(content='{\\n    \"response\": \"Thank you for the additional information! I will include your co-authorship of the workshop on recommendation systems at the ML Prague conference in the tailored section. Here’s the updated version:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Co-authored a workshop on recommendation systems at the ML Prague conference. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\",\\n    \"tailored_section\": \"Co-authored a workshop on recommendation systems at the ML Prague conference.\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2556'), 'completion_tokens': Decimal('357'), 'prompt_tokens': Decimal('2199'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-74b4d994-112f-4bd1-9832-571ef37f94ff-0', usage_metadata={'input_tokens': 2199, 'output_tokens': 357, 'total_tokens': 2556}),\n",
       " HumanMessage(content='Can you make tailored section even more concise?'),\n",
       " AIMessage(content='{\\n    \"response\": \"Sure! Here’s a more concise version of the tailored section:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Developed collaborative filtering and online ML systems for lifestyle, news, and video content, achieving a double-digit increase in key metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Analyzed terabytes of logs daily using PySpark, creating a proprietary framework for data manipulation and quality checks.\\\\n\\\\n- **Model Optimization:**  \\\\n  - Enhanced online ML models through data cleaning and feature engineering, utilizing Vowpal Wabbit and Python.  \\\\n  - Developed an offline evaluation framework based on matrix factorization to inform deployment decisions.  \\\\n  - Coauthored a library for A/B/n test evaluation to optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, leading to a publication at SIGIR 2019 and co-authoring a workshop on recommendation systems at ML Prague. Collaborated with ML engineering teams to transition prototypes to production, ensuring code quality through reviews.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2831'), 'completion_tokens': Decimal('259'), 'prompt_tokens': Decimal('2572'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-6ce76a4a-5472-47e8-a803-3af9af01de01-0', usage_metadata={'input_tokens': 2572, 'output_tokens': 259, 'total_tokens': 2831}),\n",
       " HumanMessage(content='Can you tell me what the original section is?'),\n",
       " AIMessage(content='{\\n    \"response\": \"The original section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes the following details:\\\\n\\\\n## Applied Machine Learning Scientist \\\\n\\\\nNov. 2016 - Feb. 2019\\\\n\\\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\\\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\\\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\\\n- Highlighted projects: \\\\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\\\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\\\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\\\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\\\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\\\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\\\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('3310'), 'completion_tokens': Decimal('462'), 'prompt_tokens': Decimal('2848'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-b33fddf1-d6c1-4b65-beb2-86a27bfa3226-0', usage_metadata={'input_tokens': 2848, 'output_tokens': 462, 'total_tokens': 3310}),\n",
       " HumanMessage(content='Can you tell me what the original section is?'),\n",
       " AIMessage(content='{\\n    \"response\": \"The original section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes the following details:\\\\n\\\\n## Applied Machine Learning Scientist \\\\n\\\\nNov. 2016 - Feb. 2019\\\\n\\\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\\\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\\\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\\\n- Highlighted projects: \\\\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\\\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\\\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\\\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\\\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\\\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\\\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('3789'), 'completion_tokens': Decimal('462'), 'prompt_tokens': Decimal('3327'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-c9299fd2-f72b-48fc-a4db-f4a7d76f5881-0', usage_metadata={'input_tokens': 3327, 'output_tokens': 462, 'total_tokens': 3789}),\n",
       " HumanMessage(content='Can you tell me what the tailored section is?'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None, 'tool_calls': [{'type': 'function', 'id': 'call_Eplgm9ZTwwK9QU3btFMUc7Tp', 'function': {'name': 'get_current_tailored_section', 'arguments': '{}'}}]}, response_metadata={'token_usage': {'total_tokens': Decimal('3819'), 'completion_tokens': Decimal('13'), 'prompt_tokens': Decimal('3806'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-f81234fc-78e0-4459-b151-a8fb0739366f-0', tool_calls=[{'name': 'get_current_tailored_section', 'args': {}, 'id': 'call_Eplgm9ZTwwK9QU3btFMUc7Tp', 'type': 'tool_call'}], usage_metadata={'input_tokens': 3806, 'output_tokens': 13, 'total_tokens': 3819}),\n",
       " ToolMessage(content='\\n**Applied Machine Learning Scientist**  \\n*Nov. 2016 - Feb. 2019*\\n\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\n  \\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\n\\n- **Model Optimization and Evaluation:** \\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\n\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\\n', name='get_current_tailored_section', tool_call_id='call_Eplgm9ZTwwK9QU3btFMUc7Tp'),\n",
       " AIMessage(content='{\\n    \"response\": \"The tailored section of your resume is as follows:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('4391'), 'completion_tokens': Decimal('303'), 'prompt_tokens': Decimal('4088'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-eb70382c-f97c-42d4-8a02-307694905681-0', usage_metadata={'input_tokens': 4088, 'output_tokens': 303, 'total_tokens': 4391}),\n",
       " HumanMessage(content='I forgot to mention that I co-authored a workshop on the recommendation systems at the conference ML Prague. Can you include that?'),\n",
       " AIMessage(content='{\\n    \"response\": \"Thank you for the additional information! I will include your co-authorship of the workshop on recommendation systems at the ML Prague conference in the tailored section. Here’s the updated version:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Co-authored a workshop on recommendation systems at the ML Prague conference. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\",\\n    \"tailored_section\": \"Co-authored a workshop on recommendation systems at the ML Prague conference.\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('4781'), 'completion_tokens': Decimal('357'), 'prompt_tokens': Decimal('4424'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-95aebf16-ad90-4788-a0b8-6bfa2cba58e4-0', usage_metadata={'input_tokens': 4424, 'output_tokens': 357, 'total_tokens': 4781})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_message_history(conversation_id=conversation_id).messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_4 = get_event(\"event_4.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Sure! Here’s a more concise version of the tailored section:\n",
       "\n",
       "**Applied Machine Learning Scientist**  \n",
       "*Nov. 2016 - Feb. 2019*\n",
       "\n",
       "- **Recommender Systems Development:** Developed collaborative filtering and online ML systems for lifestyle, news, and video content, achieving a double-digit increase in key metrics and reaching over half of the Czech internet population.\n",
       "  \n",
       "- **Data Processing and Analysis:** Analyzed terabytes of logs daily using PySpark, creating a proprietary framework for data manipulation and quality checks.\n",
       "\n",
       "- **Model Optimization:**  \n",
       "  - Enhanced online ML models through data cleaning and feature engineering, utilizing Vowpal Wabbit and Python.  \n",
       "  - Developed an offline evaluation framework based on matrix factorization to inform deployment decisions.  \n",
       "  - Coauthored a library for A/B/n test evaluation to optimize user engagement.\n",
       "\n",
       "- **Research and Collaboration:** Conducted research on contextual bandits, leading to a publication at SIGIR 2019 and co-authoring a workshop on recommendation systems at ML Prague. Collaborated with ML engineering teams to transition prototypes to production, ensuring code quality through reviews."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tailored Section\n"
     ]
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = handler(event_4, None)\n",
    "format_response(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You\\'re an expert resume writer. \\n\\n1. Help tailor this resume section to match job requirements.\\n2. Comunicate with the user to understand their needs.\\n3. Ask for clarification if needed. \\n\\nYou have access to the Original Section of the resume and the Job Requirements extracted from the job post. \\nMoreover, you can use a tool for getting a tailored section.\\n\\nAlways split the response to the two parts in this format:\\n{\\n    \"response\": \"The response that will be showed to the user.\",\\n    \"tailored_section\": \"If change is required, the newly tailored section. Can be empty string if no update is required.\"\\n}\\n\\n-------------------------------\\n\\nOriginal Section:\\n## Applied Machine Learning Scientist \\n\\nNov. 2016 - Feb. 2019\\n\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\n- Highlighted projects: \\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\\n\\n-------------------------------\\n\\nJob Requirements:\\n**Required Qualifications:**\\n1. Bachelor\\'s degree or equivalent practical experience.\\n2. 2 years of experience with software development in one or more programming languages, and with data structures or algorithms.\\n3. 2 years of experience with machine learning algorithms and tools (e.g., TensorFlow), artificial intelligence, deep learning, or natural language processing.\\n4. Experience with Large Language Models, NLP, or Generative AI.\\n5. Experience with Coding, Experiment Design, Data Analysis.\\n6. Experience with recommendation systems/rankings/predictions.\\n\\n**Preferred Qualifications:**\\n1. Master\\'s degree or PhD in Computer Science or related technical fields.\\n2. Experience developing accessible technologies.\\n3. Experience with C++, Statistical Analysis, Python.\\n4. Experience with quality work in either serving quality or data quality.\\n5. Experience as a data analyst/scientist.\\n6. Experience in understanding user behavior (i.e., mathematical modeling or social science background).\\n\\n**Key Technical Skills:**\\n1. Programming languages (specific languages not mentioned, but implied).\\n2. Machine learning algorithms and tools (e.g., TensorFlow).\\n3. Large Language Models, NLP, or Generative AI.\\n4. C++.\\n5. Statistical Analysis.\\n6. Python.\\n7. Data Analysis.\\n8. Experiment Design.\\n9. Recommendation systems/rankings/predictions.\\n\\n**Soft Skills:**\\n1. Versatility.\\n2. Leadership qualities.\\n3. Enthusiasm to take on new problems.\\n\\n**Education Requirements:**\\n1. Bachelor\\'s degree or equivalent practical experience (required).\\n2. Master\\'s degree or PhD in Computer Science or related technical fields (preferred).\\n\\n**Experience Level:**\\n- Minimum of 2 years of experience in software development and machine learning (required).\\n\\n**Industry-Specific Keywords:**\\n1. Software engineering.\\n2. Artificial intelligence.\\n3. Natural language processing.\\n4. Large-scale system design.\\n5. E-commerce.\\n6. User behavior modeling.\\n\\n**Responsibilities and Duties:**\\n1. Work in coding, modeling, and analysis.\\n2. Find or create the right signals for modeling.\\n3. Combine signals into a model and evaluate its merit through offline evaluation.\\n4. Integrate models into the production stack (e.g., search and shopping) and initiate live experiments.\\n\\n**Company Values or Culture Fit:**\\n- Commitment to equal employment opportunity and diversity.\\n- Emphasis on innovation and versatility in problem-solving.\\n- Focus on collaboration with the commerce ecosystem to enhance user experiences.\\n\\n'),\n",
       " HumanMessage(content='Can you tell me what the original section is?'),\n",
       " AIMessage(content='{\\n    \"response\": \"The original section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes the following details:\\\\n\\\\n## Applied Machine Learning Scientist \\\\n\\\\nNov. 2016 - Feb. 2019\\\\n\\\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\\\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\\\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\\\n- Highlighted projects: \\\\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\\\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\\\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\\\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\\\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\\\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\\\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('1564'), 'completion_tokens': Decimal('462'), 'prompt_tokens': Decimal('1102'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-8c9d3a1d-5048-406c-80f9-9f8ca059130d-0', usage_metadata={'input_tokens': 1102, 'output_tokens': 462, 'total_tokens': 1564}),\n",
       " HumanMessage(content='Can you tell me what the tailored section is?'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None, 'tool_calls': [{'type': 'function', 'id': 'call_JRHO6M7sEeZcbcdsMahN8P0L', 'function': {'name': 'get_current_tailored_section', 'arguments': '{}'}}]}, response_metadata={'token_usage': {'total_tokens': Decimal('1594'), 'completion_tokens': Decimal('13'), 'prompt_tokens': Decimal('1581'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-0949efe8-5569-4026-a361-a6040df6585f-0', tool_calls=[{'name': 'get_current_tailored_section', 'args': {}, 'id': 'call_JRHO6M7sEeZcbcdsMahN8P0L', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1581, 'output_tokens': 13, 'total_tokens': 1594}),\n",
       " ToolMessage(content='\\n**Applied Machine Learning Scientist**  \\n*Nov. 2016 - Feb. 2019*\\n\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\n  \\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\n\\n- **Model Optimization and Evaluation:** \\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\n\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\\n', name='get_current_tailored_section', tool_call_id='call_JRHO6M7sEeZcbcdsMahN8P0L'),\n",
       " AIMessage(content='{\\n    \"response\": \"The tailored section of your resume is as follows:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2166'), 'completion_tokens': Decimal('303'), 'prompt_tokens': Decimal('1863'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-1b19a4d6-5f70-4e61-b8c8-d0692ba36ca1-0', usage_metadata={'input_tokens': 1863, 'output_tokens': 303, 'total_tokens': 2166}),\n",
       " HumanMessage(content='I forgot to mention that I co-authored a workshop on the recommendation systems at the conference ML Prague. Can you include that?'),\n",
       " AIMessage(content='{\\n    \"response\": \"Thank you for the additional information! I will include your co-authorship of the workshop on recommendation systems at the ML Prague conference in the tailored section. Here’s the updated version:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Co-authored a workshop on recommendation systems at the ML Prague conference. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\",\\n    \"tailored_section\": \"Co-authored a workshop on recommendation systems at the ML Prague conference.\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2556'), 'completion_tokens': Decimal('357'), 'prompt_tokens': Decimal('2199'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-74b4d994-112f-4bd1-9832-571ef37f94ff-0', usage_metadata={'input_tokens': 2199, 'output_tokens': 357, 'total_tokens': 2556}),\n",
       " HumanMessage(content='Can you make tailored section even more concise?'),\n",
       " AIMessage(content='{\\n    \"response\": \"Sure! Here’s a more concise version of the tailored section:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Developed collaborative filtering and online ML systems for lifestyle, news, and video content, achieving a double-digit increase in key metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Analyzed terabytes of logs daily using PySpark, creating a proprietary framework for data manipulation and quality checks.\\\\n\\\\n- **Model Optimization:**  \\\\n  - Enhanced online ML models through data cleaning and feature engineering, utilizing Vowpal Wabbit and Python.  \\\\n  - Developed an offline evaluation framework based on matrix factorization to inform deployment decisions.  \\\\n  - Coauthored a library for A/B/n test evaluation to optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, leading to a publication at SIGIR 2019 and co-authoring a workshop on recommendation systems at ML Prague. Collaborated with ML engineering teams to transition prototypes to production, ensuring code quality through reviews.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2831'), 'completion_tokens': Decimal('259'), 'prompt_tokens': Decimal('2572'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-6ce76a4a-5472-47e8-a803-3af9af01de01-0', usage_metadata={'input_tokens': 2572, 'output_tokens': 259, 'total_tokens': 2831}),\n",
       " HumanMessage(content='Can you tell me what the original section is?'),\n",
       " AIMessage(content='{\\n    \"response\": \"The original section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes the following details:\\\\n\\\\n## Applied Machine Learning Scientist \\\\n\\\\nNov. 2016 - Feb. 2019\\\\n\\\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\\\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\\\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\\\n- Highlighted projects: \\\\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\\\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\\\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\\\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\\\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\\\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\\\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('3310'), 'completion_tokens': Decimal('462'), 'prompt_tokens': Decimal('2848'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-b33fddf1-d6c1-4b65-beb2-86a27bfa3226-0', usage_metadata={'input_tokens': 2848, 'output_tokens': 462, 'total_tokens': 3310}),\n",
       " HumanMessage(content='Can you tell me what the original section is?'),\n",
       " AIMessage(content='{\\n    \"response\": \"The original section of your resume is titled \\'Applied Machine Learning Scientist\\' and includes the following details:\\\\n\\\\n## Applied Machine Learning Scientist \\\\n\\\\nNov. 2016 - Feb. 2019\\\\n\\\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\\\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\\\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\\\n- Highlighted projects: \\\\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\\\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\\\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\\\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\\\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\\\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\\\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('3789'), 'completion_tokens': Decimal('462'), 'prompt_tokens': Decimal('3327'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-c9299fd2-f72b-48fc-a4db-f4a7d76f5881-0', usage_metadata={'input_tokens': 3327, 'output_tokens': 462, 'total_tokens': 3789}),\n",
       " HumanMessage(content='Can you tell me what the tailored section is?'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None, 'tool_calls': [{'type': 'function', 'id': 'call_Eplgm9ZTwwK9QU3btFMUc7Tp', 'function': {'name': 'get_current_tailored_section', 'arguments': '{}'}}]}, response_metadata={'token_usage': {'total_tokens': Decimal('3819'), 'completion_tokens': Decimal('13'), 'prompt_tokens': Decimal('3806'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-f81234fc-78e0-4459-b151-a8fb0739366f-0', tool_calls=[{'name': 'get_current_tailored_section', 'args': {}, 'id': 'call_Eplgm9ZTwwK9QU3btFMUc7Tp', 'type': 'tool_call'}], usage_metadata={'input_tokens': 3806, 'output_tokens': 13, 'total_tokens': 3819}),\n",
       " ToolMessage(content='\\n**Applied Machine Learning Scientist**  \\n*Nov. 2016 - Feb. 2019*\\n\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\n  \\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\n\\n- **Model Optimization and Evaluation:** \\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\n\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\\n', name='get_current_tailored_section', tool_call_id='call_Eplgm9ZTwwK9QU3btFMUc7Tp'),\n",
       " AIMessage(content='{\\n    \"response\": \"The tailored section of your resume is as follows:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('4391'), 'completion_tokens': Decimal('303'), 'prompt_tokens': Decimal('4088'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-eb70382c-f97c-42d4-8a02-307694905681-0', usage_metadata={'input_tokens': 4088, 'output_tokens': 303, 'total_tokens': 4391}),\n",
       " HumanMessage(content='I forgot to mention that I co-authored a workshop on the recommendation systems at the conference ML Prague. Can you include that?'),\n",
       " AIMessage(content='{\\n    \"response\": \"Thank you for the additional information! I will include your co-authorship of the workshop on recommendation systems at the ML Prague conference in the tailored section. Here’s the updated version:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.  \\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.  \\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Co-authored a workshop on recommendation systems at the ML Prague conference. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\",\\n    \"tailored_section\": \"Co-authored a workshop on recommendation systems at the ML Prague conference.\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('4781'), 'completion_tokens': Decimal('357'), 'prompt_tokens': Decimal('4424'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-95aebf16-ad90-4788-a0b8-6bfa2cba58e4-0', usage_metadata={'input_tokens': 4424, 'output_tokens': 357, 'total_tokens': 4781}),\n",
       " HumanMessage(content='Can you make tailored section even more concise?'),\n",
       " AIMessage(content='{\\n    \"response\": \"Sure! Here’s a more concise version of the tailored section:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Developed collaborative filtering and online ML systems for lifestyle, news, and video content, achieving a double-digit increase in key metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Analyzed terabytes of logs daily using PySpark, creating a proprietary framework for data manipulation and quality checks.\\\\n\\\\n- **Model Optimization:**  \\\\n  - Enhanced online ML models through data cleaning and feature engineering, utilizing Vowpal Wabbit and Python.  \\\\n  - Developed an offline evaluation framework based on matrix factorization to inform deployment decisions.  \\\\n  - Coauthored a library for A/B/n test evaluation to optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, leading to a publication at SIGIR 2019 and co-authoring a workshop on recommendation systems at ML Prague. Collaborated with ML engineering teams to transition prototypes to production, ensuring code quality through reviews.\",\\n    \"tailored_section\": \"\"\\n}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('5056'), 'completion_tokens': Decimal('259'), 'prompt_tokens': Decimal('4797'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'logprobs': None}, id='run-573b9d42-849f-4e03-b9a7-4f297555bcf9-0', usage_metadata={'input_tokens': 4797, 'output_tokens': 259, 'total_tokens': 5056})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = get_message_history(conversation_id=conversation_id).messages\n",
    "messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
