{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../shared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from handler import handler, get_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_response(response):\n",
    "    response = json.loads(response['body'])\n",
    "    print('Response')\n",
    "    display(Markdown(response['text']))\n",
    "    print('Tailored Section')\n",
    "    display(Markdown(response['tailored_section']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Applied Machine Learning Scientist \n",
       "\n",
       "Nov. 2016 - Feb. 2019\n",
       "\n",
       "- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \n",
       "- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \n",
       "- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \n",
       "- Highlighted projects: \n",
       "    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \n",
       "    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \n",
       "    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \n",
       "    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \n",
       "    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \n",
       "    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \n",
       "    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_section = \"## Applied Machine Learning Scientist \\n\\nNov. 2016 - Feb. 2019\\n\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\n- Highlighted projects: \\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\"\n",
    "display(Markdown(original_section))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "**Applied Machine Learning Scientist**  \n",
       "*Nov. 2016 - Feb. 2019*\n",
       "\n",
       "- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\n",
       "  \n",
       "- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\n",
       "\n",
       "- **Model Optimization and Evaluation:** \n",
       "  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\n",
       "  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\n",
       "  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\n",
       "\n",
       "- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tailored_section = '\\n**Applied Machine Learning Scientist**  \\n*Nov. 2016 - Feb. 2019*\\n\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\n  \\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\n\\n- **Model Optimization and Evaluation:** \\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\n\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\\n'\n",
    "display(Markdown(tailored_section))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event(file_name):\n",
    "    path = f\"events/{file_name}\"\n",
    "    with open(path, 'r') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_1 = get_event(\"event_1.json\")\n",
    "conversation_id = json.loads(event_1['body'])['conversationId']\n",
    "user_id = event_1[\"requestContext\"][\"authorizer\"][\"claims\"][\"sub\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='{\"text\": \"\\\\nHi! \\\\n\\\\nI\\'m here to help you tailor this section. I have access to the:\\\\n\\\\n- hiring criteria, \\\\n- original section, \\\\n- current tailored section, \\\\n- the whole resume.\\\\n\\\\nHow can I help you?\\\\n\", \"tailored_section\": \"\"}')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_message_history(user_id=user_id, session_id=conversation_id).messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='{\"text\": \"Sure! Here is the text of the original section:\\\\n\\\\n## Applied Machine Learning Scientist \\\\n\\\\nNov. 2016 - Feb. 2019\\\\n\\\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\\\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\\\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\\\n- Highlighted projects: \\\\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\\\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\\\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\\\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\\\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\\\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\\\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\\\\n\", \"tailored_section\": \"\"}' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 452, 'prompt_tokens': 1024, 'total_tokens': 1476, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784', 'finish_reason': 'stop', 'logprobs': None} id='run-7d3562c1-9577-4879-8a74-24b27cb9fffb-0' usage_metadata={'input_tokens': 1024, 'output_tokens': 452, 'total_tokens': 1476}\n",
      "{'statusCode': 200, 'headers': {'Access-Control-Allow-Headers': '*', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Methods': '*'}, 'body': '{\"text\": \"Sure! Here is the text of the original section:\\\\n\\\\n## Applied Machine Learning Scientist \\\\n\\\\nNov. 2016 - Feb. 2019\\\\n\\\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\\\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\\\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\\\n- Highlighted projects: \\\\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\\\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\\\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\\\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\\\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\\\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\\\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\\\\n\", \"tailored_section\": \"\"}'}\n",
      "Response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Sure! Here is the text of the original section:\n",
       "\n",
       "## Applied Machine Learning Scientist \n",
       "\n",
       "Nov. 2016 - Feb. 2019\n",
       "\n",
       "- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \n",
       "- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \n",
       "- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \n",
       "- Highlighted projects: \n",
       "    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \n",
       "    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \n",
       "    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \n",
       "    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \n",
       "    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \n",
       "    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \n",
       "    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tailored Section\n"
     ]
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = handler(event_1, None)\n",
    "print(response)\n",
    "format_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='{\"text\": \"\\\\nHi! \\\\n\\\\nI\\'m here to help you tailor this section. I have access to the:\\\\n\\\\n- hiring criteria, \\\\n- original section, \\\\n- current tailored section, \\\\n- the whole resume.\\\\n\\\\nHow can I help you?\\\\n\", \"tailored_section\": \"\"}'),\n",
       " HumanMessage(content='Can you tell me what the text of the original section is?'),\n",
       " AIMessage(content='{\"text\": \"Sure! Here is the text of the original section:\\\\n\\\\n## Applied Machine Learning Scientist \\\\n\\\\nNov. 2016 - Feb. 2019\\\\n\\\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\\\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\\\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\\\n- Highlighted projects: \\\\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\\\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\\\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\\\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\\\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\\\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\\\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\\\\n\", \"tailored_section\": \"\"}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('1476'), 'completion_tokens': Decimal('452'), 'prompt_tokens': Decimal('1024'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784', 'logprobs': None}, id='run-7d3562c1-9577-4879-8a74-24b27cb9fffb-0', usage_metadata={'input_tokens': 1024, 'output_tokens': 452, 'total_tokens': 1476})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_message_history(user_id=user_id, session_id=conversation_id).messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_2 = get_event(\"event_2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='{\"text\": \"Certainly! Here is the text of the tailored section:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\\\\n\", \"tailored_section\": \"\"}' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 299, 'prompt_tokens': 1493, 'total_tokens': 1792, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784', 'finish_reason': 'stop', 'logprobs': None} id='run-74f1aef2-279d-4e7c-80e6-e66ae9ae72f5-0' usage_metadata={'input_tokens': 1493, 'output_tokens': 299, 'total_tokens': 1792}\n",
      "Response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Certainly! Here is the text of the tailored section:\n",
       "\n",
       "**Applied Machine Learning Scientist**  \n",
       "*Nov. 2016 - Feb. 2019*\n",
       "\n",
       "- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\n",
       "  \n",
       "- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\n",
       "\n",
       "- **Model Optimization and Evaluation:**  \n",
       "  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\n",
       "  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\n",
       "  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\n",
       "\n",
       "- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tailored Section\n"
     ]
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = handler(event_2, None)\n",
    "format_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='{\"text\": \"\\\\nHi! \\\\n\\\\nI\\'m here to help you tailor this section. I have access to the:\\\\n\\\\n- hiring criteria, \\\\n- original section, \\\\n- current tailored section, \\\\n- the whole resume.\\\\n\\\\nHow can I help you?\\\\n\", \"tailored_section\": \"\"}'),\n",
       " HumanMessage(content='Can you tell me what the text of the original section is?'),\n",
       " AIMessage(content='{\"text\": \"Sure! Here is the text of the original section:\\\\n\\\\n## Applied Machine Learning Scientist \\\\n\\\\nNov. 2016 - Feb. 2019\\\\n\\\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\\\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\\\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\\\n- Highlighted projects: \\\\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\\\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\\\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\\\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\\\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\\\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\\\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\\\\n\", \"tailored_section\": \"\"}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('1476'), 'completion_tokens': Decimal('452'), 'prompt_tokens': Decimal('1024'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784', 'logprobs': None}, id='run-7d3562c1-9577-4879-8a74-24b27cb9fffb-0', usage_metadata={'input_tokens': 1024, 'output_tokens': 452, 'total_tokens': 1476}),\n",
       " HumanMessage(content='Can you tell me what the tailored section is?'),\n",
       " AIMessage(content='{\"text\": \"Certainly! Here is the text of the tailored section:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\\\\n\", \"tailored_section\": \"\"}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('1792'), 'completion_tokens': Decimal('299'), 'prompt_tokens': Decimal('1493'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784', 'logprobs': None}, id='run-74f1aef2-279d-4e7c-80e6-e66ae9ae72f5-0', usage_metadata={'input_tokens': 1493, 'output_tokens': 299, 'total_tokens': 1792})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_message_history(user_id=user_id, session_id=conversation_id).messages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_3 = get_event(\"event_3.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='{\"text\": \"Got it! I will include your co-authorship of the workshop on recommendation systems at the ML Prague conference. Here’s the updated tailored section:\\\\n\", \"tailored_section\": \"**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Co-authored a workshop on recommendation systems at the ML Prague conference. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\"}' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 328, 'prompt_tokens': 1825, 'total_tokens': 2153, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784', 'finish_reason': 'stop', 'logprobs': None} id='run-26725fee-ddaa-4424-845f-fe8eb3eb97c5-0' usage_metadata={'input_tokens': 1825, 'output_tokens': 328, 'total_tokens': 2153}\n",
      "Response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Got it! I will include your co-authorship of the workshop on recommendation systems at the ML Prague conference. Here’s the updated tailored section:\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tailored Section\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Applied Machine Learning Scientist**  \n",
       "*Nov. 2016 - Feb. 2019*\n",
       "\n",
       "- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\n",
       "  \n",
       "- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\n",
       "\n",
       "- **Model Optimization and Evaluation:**  \n",
       "  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\n",
       "  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\n",
       "  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\n",
       "\n",
       "- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Co-authored a workshop on recommendation systems at the ML Prague conference. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = handler(event_3, None)\n",
    "format_response(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='{\"text\": \"\\\\nHi! \\\\n\\\\nI\\'m here to help you tailor this section. I have access to the:\\\\n\\\\n- hiring criteria, \\\\n- original section, \\\\n- current tailored section, \\\\n- the whole resume.\\\\n\\\\nHow can I help you?\\\\n\", \"tailored_section\": \"\"}'),\n",
       " HumanMessage(content='Can you tell me what the text of the original section is?'),\n",
       " AIMessage(content='{\"text\": \"Sure! Here is the text of the original section:\\\\n\\\\n## Applied Machine Learning Scientist \\\\n\\\\nNov. 2016 - Feb. 2019\\\\n\\\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\\\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\\\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\\\n- Highlighted projects: \\\\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\\\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\\\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\\\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\\\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\\\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\\\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\\\\n\", \"tailored_section\": \"\"}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('1476'), 'completion_tokens': Decimal('452'), 'prompt_tokens': Decimal('1024'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784', 'logprobs': None}, id='run-7d3562c1-9577-4879-8a74-24b27cb9fffb-0', usage_metadata={'input_tokens': 1024, 'output_tokens': 452, 'total_tokens': 1476}),\n",
       " HumanMessage(content='Can you tell me what the tailored section is?'),\n",
       " AIMessage(content='{\"text\": \"Certainly! Here is the text of the tailored section:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\\\\n\", \"tailored_section\": \"\"}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('1792'), 'completion_tokens': Decimal('299'), 'prompt_tokens': Decimal('1493'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784', 'logprobs': None}, id='run-74f1aef2-279d-4e7c-80e6-e66ae9ae72f5-0', usage_metadata={'input_tokens': 1493, 'output_tokens': 299, 'total_tokens': 1792}),\n",
       " HumanMessage(content='I forgot to mention that I co-authored a workshop on the recommendation systems at the conference ML Prague. Can you include that?'),\n",
       " AIMessage(content='{\"text\": \"Got it! I will include your co-authorship of the workshop on recommendation systems at the ML Prague conference. Here’s the updated tailored section:\\\\n\", \"tailored_section\": \"**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Co-authored a workshop on recommendation systems at the ML Prague conference. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\"}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2153'), 'completion_tokens': Decimal('328'), 'prompt_tokens': Decimal('1825'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784', 'logprobs': None}, id='run-26725fee-ddaa-4424-845f-fe8eb3eb97c5-0', usage_metadata={'input_tokens': 1825, 'output_tokens': 328, 'total_tokens': 2153})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_message_history(user_id=user_id, session_id=conversation_id).messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_4 = get_event(\"event_4.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_5poKAoWDo26HgdUuF31Z0YpE', 'function': {'arguments': '{}', 'name': 'get_resume'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 2170, 'total_tokens': 2180, 'completion_tokens_details': {'reasoning_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-1f8f3a62-9bb8-44fa-ae7a-9175240593df-0' tool_calls=[{'name': 'get_resume', 'args': {}, 'id': 'call_5poKAoWDo26HgdUuF31Z0YpE', 'type': 'tool_call'}] usage_metadata={'input_tokens': 2170, 'output_tokens': 10, 'total_tokens': 2180}\n",
      "Response\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I'm unable to provide the original resume as it seems there was an issue retrieving it. However, I can assist you with any specific sections or details you need help with. Let me know how you'd like to proceed!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tailored Section\n"
     ]
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = handler(event_4, None)\n",
    "format_response(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='{\"text\": \"\\\\nHi! \\\\n\\\\nI\\'m here to help you tailor this section. I have access to the:\\\\n\\\\n- hiring criteria, \\\\n- original section, \\\\n- current tailored section, \\\\n- the whole resume.\\\\n\\\\nHow can I help you?\\\\n\", \"tailored_section\": \"\"}'),\n",
       " HumanMessage(content='Can you tell me what the text of the original section is?'),\n",
       " AIMessage(content='{\"text\": \"Sure! Here is the text of the original section:\\\\n\\\\n## Applied Machine Learning Scientist \\\\n\\\\nNov. 2016 - Feb. 2019\\\\n\\\\n- Recommender Systems Development: Worked on recommender systems (e.g., collaborative filtering, online ML learning) for lifestyle, news, and video content, reaching over half of the Czech internet population. This resulted in a substantial double-digit increase in key performance metrics. \\\\n- Data Processing and Analysis: Processed and analyzed terabytes of logs daily using an on-premise cluster. Developed and maintained a proprietary framework for data manipulation and quality checks. PySpark \\\\n- Collaboration and Code Review: Worked closely with the ML engineering team to reimplement prototypes into the production environment and review production code. Participated in planning and prioritization meetings. \\\\n- Highlighted projects: \\\\n    * Model Improvement: Continuously improved online machine learning models through data cleaning, feature selection/extraction/engineering techniques, and conducting numerous offline and online tests. Vowpal Wabbit \\\\n    * Recommendation Diversification: Developed an approach for recommendation diversification based on clustering of semantic and text vectors. scikit-learn \\\\n    * Hyperparameter Optimization: Developed an approach based on the Nelder-Mead method, enabling real-time adjustments based on online metrics (e.g., user engagement). Python \\\\n    * Offline Evaluation Framework: Created a framework for offline evaluation of models based on matrix factorization, leading to informed deployment and improved performance in online metrics. Python \\\\n    * A/B/n Test Evaluation: Coauthored a proprietary library for A/B/n test evaluation based on a frequentist approach. Designed, evaluated, and interpreted results of A/B/n tests. Python, Pyspark, Statmodels \\\\n    * Production Implementation: Implemented the machine learning component of a recommender system based on matrix factorization into production, significantly optimizing its memory efficiency and performance. NumPy, multiprocessing \\\\n    * Contextual Bandits Research: Focused research on the field of contextual bandits, leading to collaboration with the counterpart research department and a publication (short paper) at SIGIR 2019.\\\\n\", \"tailored_section\": \"\"}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('1476'), 'completion_tokens': Decimal('452'), 'prompt_tokens': Decimal('1024'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784', 'logprobs': None}, id='run-7d3562c1-9577-4879-8a74-24b27cb9fffb-0', usage_metadata={'input_tokens': 1024, 'output_tokens': 452, 'total_tokens': 1476}),\n",
       " HumanMessage(content='Can you tell me what the tailored section is?'),\n",
       " AIMessage(content='{\"text\": \"Certainly! Here is the text of the tailored section:\\\\n\\\\n**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\\\\n\", \"tailored_section\": \"\"}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('1792'), 'completion_tokens': Decimal('299'), 'prompt_tokens': Decimal('1493'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784', 'logprobs': None}, id='run-74f1aef2-279d-4e7c-80e6-e66ae9ae72f5-0', usage_metadata={'input_tokens': 1493, 'output_tokens': 299, 'total_tokens': 1792}),\n",
       " HumanMessage(content='I forgot to mention that I co-authored a workshop on the recommendation systems at the conference ML Prague. Can you include that?'),\n",
       " AIMessage(content='{\"text\": \"Got it! I will include your co-authorship of the workshop on recommendation systems at the ML Prague conference. Here’s the updated tailored section:\\\\n\", \"tailored_section\": \"**Applied Machine Learning Scientist**  \\\\n*Nov. 2016 - Feb. 2019*\\\\n\\\\n- **Recommender Systems Development:** Engineered collaborative filtering and online machine learning recommender systems for lifestyle, news, and video content, achieving a double-digit increase in key performance metrics and reaching over half of the Czech internet population.\\\\n  \\\\n- **Data Processing and Analysis:** Processed and analyzed terabytes of logs daily using PySpark on an on-premise cluster. Developed a proprietary framework for data manipulation and quality checks, ensuring high data integrity for machine learning applications.\\\\n\\\\n- **Model Optimization and Evaluation:**  \\\\n  - Improved online machine learning models through data cleaning, feature engineering, and rigorous offline/online testing, utilizing tools such as Vowpal Wabbit and Python.\\\\n  - Developed a framework for offline evaluation of models based on matrix factorization, enhancing deployment decisions and online performance.\\\\n  - Coauthored a library for A/B/n test evaluation, applying statistical methods to interpret results and optimize user engagement.\\\\n\\\\n- **Research and Collaboration:** Conducted research on contextual bandits, collaborating with the research department, resulting in a publication at SIGIR 2019. Co-authored a workshop on recommendation systems at the ML Prague conference. Worked closely with ML engineering teams to transition prototypes to production, ensuring code quality through reviews and participation in planning meetings.\"}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2153'), 'completion_tokens': Decimal('328'), 'prompt_tokens': Decimal('1825'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784', 'logprobs': None}, id='run-26725fee-ddaa-4424-845f-fe8eb3eb97c5-0', usage_metadata={'input_tokens': 1825, 'output_tokens': 328, 'total_tokens': 2153}),\n",
       " HumanMessage(content='Can you tell me what the original resume is?'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None, 'tool_calls': [{'type': 'function', 'id': 'call_5poKAoWDo26HgdUuF31Z0YpE', 'function': {'name': 'get_resume', 'arguments': '{}'}}]}, response_metadata={'token_usage': {'total_tokens': Decimal('2180'), 'completion_tokens': Decimal('10'), 'prompt_tokens': Decimal('2170'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784', 'logprobs': None}, id='run-1f8f3a62-9bb8-44fa-ae7a-9175240593df-0', tool_calls=[{'name': 'get_resume', 'args': {}, 'id': 'call_5poKAoWDo26HgdUuF31Z0YpE', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2170, 'output_tokens': 10, 'total_tokens': 2180}),\n",
       " ToolMessage(content='bla', name='get_resume', tool_call_id='call_5poKAoWDo26HgdUuF31Z0YpE'),\n",
       " AIMessage(content='{\"text\": \"I\\'m unable to provide the original resume as it seems there was an issue retrieving it. However, I can assist you with any specific sections or details you need help with. Let me know how you\\'d like to proceed!\", \"tailored_section\": \"\"}', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'total_tokens': Decimal('2244'), 'completion_tokens': Decimal('55'), 'prompt_tokens': Decimal('2189'), 'completion_tokens_details': {'reasoning_tokens': Decimal('0')}}, 'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784', 'logprobs': None}, id='run-b646e72b-03cc-4bd9-9857-b63f07977a56-0', usage_metadata={'input_tokens': 2189, 'output_tokens': 55, 'total_tokens': 2244})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_message_history(user_id=user_id, session_id=conversation_id).messages\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
